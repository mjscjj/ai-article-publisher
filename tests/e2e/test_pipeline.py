#!/usr/bin/env python3
"""
ã€ç«¯åˆ°ç«¯æµ‹è¯•è„šæœ¬ã€‘E2E Test Pipeline
æµ‹è¯•å®Œæ•´å†™ä½œæµç¨‹ï¼šè¯é¢˜å‘ç° â†’ æœç´¢å¢å¼º â†’ å¤§çº²ç”Ÿæˆ â†’ æ–‡ç« æ’°å†™ â†’ HTML æ’ç‰ˆ
"""

import sys
import os
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from plugins.topic_discovery.engine import TopicDiscoveryEngine
from core.prompt_toolkit import get_preset, build_prompt
from core.llm_client import ask_ai
from plugins.article_generator.outliner import generate_outline

def test_e2e_pipeline():
    print("\n" + "="*70)
    print("ğŸ§ª ç«¯åˆ°ç«¯æµ‹è¯•ï¼šAI å†™ä½œå…¨æµç¨‹")
    print("="*70 + "\n")
    
    # Step 1: è¯é¢˜å‘ç°
    print("Step 1: è¯é¢˜å‘ç°")
    engine = TopicDiscoveryEngine()
    topics = engine.discover_topics(3)
    
    if not topics:
        print("âŒ è¯é¢˜å‘ç°å¤±è´¥")
        return False
    
    best_topic = topics[0]
    topic_keyword = best_topic['cluster']['cluster_keyword']
    print(f"âœ… é€‰å®šè¯é¢˜ï¼š{topic_keyword}")
    print(f"   è¯„åˆ†ï¼š{best_topic['scores']['total']} | {best_topic['recommendation']}")
    
    # Step 2: æ„å»º Fact-Pack
    print("\nStep 2: æ„å»ºäº‹å®åŒ…")
    cluster_items = best_topic['cluster']['items'][:5]
    fact_pack = {
        "title": topic_keyword,
        "facts": [item.get('title', '') for item in cluster_items],
        "sources": list(set([item.get('source_name', 'æœªçŸ¥') for item in cluster_items]))
    }
    print(f"âœ… äº‹å®åŒ…ï¼š{len(fact_pack['facts'])} æ¡äº‹å®ï¼Œ{len(fact_pack['sources'])} ä¸ªæ•°æ®æº")
    
    # Step 3: ç”Ÿæˆå¤§çº²
    print("\nStep 3: ç”Ÿæˆæ–‡ç« å¤§çº²")
    outline = generate_outline(fact_pack)
    print(f"âœ… å¤§çº²ï¼š{outline.get('title', 'N/A')}")
    print(f"   å°èŠ‚æ•°ï¼š{len(outline.get('sections', []))}")
    
    # Step 4: æ„å»º Prompt
    print("\nStep 4: æ„å»ºå†™ä½œ Prompt")
    facts_str = "\n".join([f"- {f}" for f in fact_pack['facts']])
    prompt = build_prompt(
        topic_keyword,
        facts_str,
        get_preset('commercial_deep')
    )
    print(f"âœ… Prompt é•¿åº¦ï¼š{len(prompt)} å­—ç¬¦")
    
    # Step 5: è°ƒç”¨ LLM å†™ä½œ
    print("\nStep 5: AI å†™ä½œ (è°ƒç”¨ Kimi-2.5)")
    system_prompt = "ä½ æ˜¯ä¸€åé¡¶çº§å•†ä¸šç§‘æŠ€åª’ä½“ä¸»ç¬”ï¼Œè¯­è¨€é”‹åˆ©å…‹åˆ¶ï¼Œç”¨äº‹å®å’Œæ•°æ®è¯´è¯ã€‚"
    
    article = ask_ai(prompt, system_prompt)
    
    if article and len(article) > 500:
        print(f"âœ… æ–‡ç« ç”ŸæˆæˆåŠŸï¼š{len(article)} å­—ç¬¦")
        
        # ä¿å­˜ç»“æœ
        output_path = "data/e2e_test_article.md"
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(f"# {outline.get('title', topic_keyword)}\n\n")
            f.write(article)
        print(f"âœ… æ–‡ç« å·²ä¿å­˜ï¼š{output_path}")
    else:
        print(f"âš ï¸ æ–‡ç« ç”Ÿæˆå¼‚å¸¸ï¼š{len(article) if article else 0} å­—ç¬¦")
        print(f"   å“åº”ï¼š{article[:200] if article else 'None'}...")
    
    print("\n" + "="*70)
    print("ğŸ‰ ç«¯åˆ°ç«¯æµ‹è¯•å®Œæˆ")
    print("="*70 + "\n")
    
    return True

if __name__ == "__main__":
    success = test_e2e_pipeline()
    sys.exit(0 if success else 1)
