#!/usr/bin/env python3
"""
ã€B ç«™è¯„è®ºé‡‡é›†å™¨ã€‘bilibili_collector.py
é€šè¿‡ RSSHub èŽ·å– B ç«™è§†é¢‘è¯„è®ºï¼Œæ•æ‰å¹´è½»ç¾¤ä½“æƒ…ç»ªä¸Žå¼¹å¹•æ–‡åŒ–ã€‚

æ›¿ä»£å°çº¢ä¹¦æ–¹æ¡ˆä¹‹ä¸€ï¼šB ç«™ç”¨æˆ·ä»¥ Z ä¸–ä»£ä¸ºä¸»ï¼Œè¯„è®ºè´¨é‡é«˜ã€æ¢—æ–‡åŒ–ä¸°å¯Œã€‚
"""

import urllib.request
import urllib.parse
import json
from typing import List, Dict, Any

RSSHUB_BASE = "http://localhost:1200"

def _fetch_rsshub(route: str) -> List[Dict]:
    """å†…éƒ¨é€šç”¨ï¼šå‘ RSSHub è¯·æ±‚ JSON æ ¼å¼æ•°æ®"""
    url = f"{RSSHUB_BASE}{route}?format=json"
    try:
        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0 (AI-Bot)'})
        with urllib.request.urlopen(req, timeout=15) as response:
            data = json.loads(response.read().decode('utf-8'))
            return data.get('items', [])
    except Exception as e:
        print(f"[B ç«™é‡‡é›†å™¨] âš ï¸ è¯·æ±‚ {route} å¤±è´¥ï¼š{e}")
        return []

def search_bilibili_videos(keyword: str, limit: int = 5) -> List[Dict[str, Any]]:
    """
    æœç´¢ B ç«™ç›¸å…³è§†é¢‘
    
    æ³¨æ„ï¼šRSSHub çš„ B ç«™æœç´¢è·¯ç”±å¯èƒ½è¿”å›ž HTMLï¼Œä½¿ç”¨æŽ’è¡Œæ¦œ/åˆ†åŒºä½œä¸ºæ›¿ä»£
    
    Args:
        keyword: æœç´¢å…³é”®è¯
        limit: è¿”å›žè§†é¢‘æ•°é‡
    
    Returns:
        è§†é¢‘åˆ—è¡¨ï¼ŒåŒ…å«æ ‡é¢˜ã€UP ä¸»ã€æ’­æ”¾é‡ç­‰
    """
    # ä½¿ç”¨ B ç«™æŽ’è¡Œæ¦œä½œä¸ºæ›¿ä»£ (æ›´ç¨³å®š)
    # route = f"/bilibili/search/video/{keyword}"  # å¯èƒ½è¿”å›ž HTML
    route = "/bilibili/ranking/0/3"  # å…¨åŒºæŽ’è¡Œ
    
    items = _fetch_rsshub(route)
    results = []
    
    for item in items[:limit]:
        desc = item.get('description', '')
        
        results.append({
            "platform": "Bilibili",
            "title": item.get('title', '')[:80],
            "author": item.get('author', 'æœªçŸ¥'),
            "pub_date": item.get('pubDate', ''),
            "link": item.get('link', ''),
            "description": desc[:300] if desc else '',
        })
    
    return results

def extract_video_comments(video_url: str, limit: int = 10) -> List[Dict[str, str]]:
    """
    ä»Žå•ä¸ªè§†é¢‘ä¸­æå–çƒ­é—¨è¯„è®º (éœ€è¦ B ç«™ APIï¼Œå½“å‰ç”¨ Mock é™çº§)
    
    TODO: åŽç»­å¯æŽ¥å…¥ B ç«™å®˜æ–¹ API æˆ–ç¬¬ä¸‰æ–¹æœåŠ¡
    """
    # ç”±äºŽ RSSHub ä¸ç›´æŽ¥æä¾›è¯„è®ºæŽ¥å£ï¼Œè¿™é‡Œè¿”å›žæ¨¡æ‹Ÿæ•°æ®
    # å®žé™…ä½¿ç”¨æ—¶å¯é€šè¿‡ video_url ä¸­çš„ BV å·è°ƒç”¨ B ç«™ API
    print(f"[B ç«™é‡‡é›†å™¨] âš ï¸ è¯„è®ºæå–åŠŸèƒ½æš‚ä¸æ”¯æŒï¼Œè¿”å›žè§†é¢‘å…ƒæ•°æ®")
    return []

def sniff_bilibili_emotions(keyword: str, top_n: int = 5) -> Dict[str, Any]:
    """
    å¯¹å¤–ç»Ÿä¸€æš´éœ²çš„ä¸»å‡½æ•°ï¼šæœç´¢ B ç«™è§†é¢‘ â†’ æå–è¯„è®º â†’ åˆ†æžæƒ…ç»ª
    
    Args:
        keyword: æœç´¢å…³é”®è¯
        top_n: èŽ·å–å‰ N ä¸ªè§†é¢‘
    
    Returns:
        ç»“æž„åŒ–æ•°æ®ï¼š
        {
            "keyword": "...",
            "videos": [...],
            "hot_comments": [...]  # çƒ­é—¨è¯„è®º
        }
    """
    print(f"[B ç«™é‡‡é›†å™¨] ðŸ” æ­£åœ¨æœç´¢ B ç«™å…³äºŽã€{keyword}ã€‘çš„è§†é¢‘...")
    
    videos = search_bilibili_videos(keyword, limit=top_n)
    if not videos:
        return {"keyword": keyword, "videos": [], "hot_comments": []}
    
    # æå–è¯„è®º (å½“å‰ä¸º Mock)
    all_comments = []
    for video in videos:
        comments = extract_video_comments(video['link'], limit=5)
        all_comments.extend(comments)
    
    print(f"[B ç«™é‡‡é›†å™¨] âœ… å…±èŽ·å– {len(videos)} ä¸ªè§†é¢‘")
    
    return {
        "keyword": keyword,
        "videos": videos,
        "hot_comments": all_comments,
    }

if __name__ == "__main__":
    import sys
    kw = sys.argv[1] if len(sys.argv) > 1 else "AI æ•™è‚²"
    res = sniff_bilibili_emotions(kw, top_n=5)
    print(json.dumps(res, ensure_ascii=False, indent=2))
