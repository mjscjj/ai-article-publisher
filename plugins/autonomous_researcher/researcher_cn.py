#!/usr/bin/env python3
"""
ã€ Autonomous Researcher (Triad-CN Version) ã€‘
ç»“åˆä¸­å›½äº’è”ç½‘ç”Ÿæ€ç‰¹æ€§çš„ä¸‰è½¨åˆ¶æ™ºèƒ½ç‰¹å·¥ã€‚
è´Ÿè´£æŠŠå¤§å‘½é¢˜æ‹†è§£ä¸º 3 æ¡å¹¶è¡Œçš„æƒ…æŠ¥èˆªçº¿ï¼š
1. å®è§‚æ”¿ç­–/å®˜åª’ (Baidu MCP)
2. Cç«¯ç—›ç‚¹/æƒ…ç»ªå…±é¸£ (Xiaohongshu MCP)
3. è¡Œä¸šæ ç²¾/é«˜çŸ¥ç¤¾ç¾¤ (RSSHub Zhihu/36kr)
"""
import json
import re

# å¼•å…¥æˆ‘ä»¬åˆšæ‰åˆ›å»ºçš„ä¾›åº”å•†
from providers.baidu_mcp import BaiduProvider
from providers.xiaohongshu_mcp import XiaohongshuProvider
from providers.rsshub import RSSHubProvider

class AutonomousResearcherCN:
    def __init__(self, llm_callable):
        self.llm = llm_callable
        self.baidu = BaiduProvider()
        self.xhs = XiaohongshuProvider()
        self.rss = RSSHubProvider()
        
    def _generate_triad_queries(self, topic):
        """è®© AI é’ˆå¯¹è¿™ä¸‰å¤§æŠ¤æ³•äº§å‡ºç‰¹å®šè§’åº¦çš„æœç´¢è¯"""
        sys = "ä½ æ˜¯é¡¶çº§çš„å†…å®¹æ“ç›˜æ‰‹ã€‚è¿”å›åˆæ³•çš„ JSON å¯¹è±¡ã€‚ä¸å‡†å›ç­”é™¤äº† JSON ä»¥å¤–çš„å¤šä½™æ–‡å­—ã€‚"
        prompt = f"""
ä»»åŠ¡ï¼šä¸ºæ–°å•†ä¸šæ–‡ç« ã€{topic}ã€‘é…ç½®ä¸‰å¤§ç¤¾äº¤é˜µåœ°ï¼ˆç™¾åº¦æ–°é—»ã€å°çº¢ä¹¦ã€çŸ¥ä¹å…¨ç½‘ï¼‰çš„å®šå‘çˆ†ç ´æœç´¢è¯ã€‚

ç™¾åº¦ï¼šç”¨äºæœå®è§‚æ”¿ç­–ã€è¡Œä¸šæŠ•èèµ„ï¼ˆä¸“ä¸šå†°å†·è¯æ±‡ï¼‰ã€‚
å°çº¢ä¹¦ï¼šç”¨äºæœ C ç«¯æ‰“å·¥äººçš„æƒ…ç»ªå…±é¸£ã€åæ§½ã€æé’±æˆ–é¿å‘ï¼ˆå¤§ç™½è¯æƒ…ç»ªè¯æ±‡ï¼‰ã€‚
çŸ¥ä¹ï¼šæå–é«˜èµçš„è£…é€¼é‡‘å¥ä¸è¡Œä¸šé»‘è¯ï¼ˆæ€è¾¨å‹é—®é¢˜ï¼‰ã€‚

è¿”å›æ ¼å¼:
{{
  "baidu": ["å®è§‚è¯1"],
  "xiaohongshu": ["æƒ…ç»ªè¯1"],
  "zhihu": ["æ€è¾¨è¯1"]
}}
"""
        try:
            res = self.llm(prompt, sys)
            match = re.search(r'\{.*\}', res, re.S)
            if match:
                return json.loads(match.group(0))
        except Exception as e:
            print("æ‹†è¯JSONå‡ºé”™", e)
        return {"baidu": [f"{topic} æ”¿ç­–è¶‹åŠ¿"], "xiaohongshu": [f"{topic} ç„¦è™‘çœŸå®ä½“éªŒ"], "zhihu": [f"å¦‚ä½•çœ‹å¾… {topic}"]}

    def _synthesize(self, topic, kb_data: dict):
        """å°†ä¸‰è½¨æƒ…æŠ¥å‹åˆ¶ä¸ºä¸€ç‚‰"""
        raw_str = f"""
ã€ç™¾åº¦æ–°é—»/å®˜æ–¹æ¥æºã€‘
{" / ".join(kb_data.get('baidu', []))}

ã€å°çº¢ä¹¦çœŸå®ç—›ç‚¹/é¿å‘ã€‘
{" / ".join(kb_data.get('xiaohongshu', []))}

ã€çŸ¥ä¹/è¡Œä¸šæ·±æ½œäº‰è®ºã€‘
{" / ".join(kb_data.get('zhihu', []))}
"""
        prompt = f"è¿™æ˜¯ç³»ç»Ÿçˆ¬è™«ä»å›½å†…ä¸‰å¤§å¹³å°å¼ºè¡Œå¸¦å›çš„å…³äºã€{topic}ã€‘çš„å¤šç»´ç¢ç‰‡ï¼š\n{raw_str[:15000]}\n\nã€ä»»åŠ¡ã€‘è¯·ç²¾ç‚¼æˆ 4-6 æ¡æå…·ä¸­å›½èŒåœºæˆ–å•†ä¸šåˆ‡è‚¤ä¹‹ç—›çš„æ–°é—»äº‹å®/ç—›ç‚¹åŒ…ï¼ˆFact-Packï¼‰ã€‚å¿…é¡»ä½“ç°å®è§‚å†°å†·å¯¹æ¯”ä¸ªä½“ä¼¤ç—›çš„æ’•è£‚æ„Ÿã€‚ä¸å‡†åºŸè¯ã€‚"
        sys = "ä½ æ˜¯æ·±ç½‘é‡‘ç‰Œç¼–è¾‘ã€‚"
        return self.llm(prompt, sys)

    def run(self, topic):
        print(f"\nğŸš€ [Autonomous Researcher Triad-CN] V3-ä¸‰è½¨åˆ¶å›½å†…æ¢é’ˆç»„ç¾¤å¯åŠ¨ï¼å‘½é¢˜ï¼š{topic}")
        queries = self._generate_triad_queries(topic)
        print(f"ğŸ¯ AI å¤šç»´çˆ†ç ´æŒ‡ä»¤å·²ä¸‹è¾¾ï¼š\n  [ç™¾åº¦] æ‰«é›·è¯ -> {queries.get('baidu')}\n  [å°çº¢ä¹¦] æƒ…ç»ªè¯ -> {queries.get('xiaohongshu')}\n  [çŸ¥ä¹] æ ç²¾è¯ -> {queries.get('zhihu')}\n")

        kb = {"baidu": [], "xiaohongshu": [], "zhihu": []}
        
        # 1. Baidu
        print(f"  ğŸ•·ï¸ (è½¨è¿¹ 1) å¯åŠ¨ Baidu MCP æ¢æµ‹å®˜åª’/å®è§‚é¢...")
        for q in queries.get("baidu", []):
            res = self.baidu.search(q)
            if isinstance(res, list): kb["baidu"].extend(res)
            
        # 2. å°çº¢ä¹¦
        print(f"  ğŸ•·ï¸ (è½¨è¿¹ 2) å¯åŠ¨ Xiaohongshu MCP æ”¶å‰²æ‰“å·¥äººç ´é˜²æƒ…ç»ª...")
        for q in queries.get("xiaohongshu", []):
            res = self.xhs.search(q)
            if isinstance(res, list): kb["xiaohongshu"].extend(res)
            
        # 3. çŸ¥ä¹ RSS
        print(f"  ğŸ•·ï¸ (è½¨è¿¹ 3) å¯åŠ¨ RSSHub å¼•æ“æŠ“å–çŸ¥ä¹é«˜èµæ·±æ–‡...")
        for q in queries.get("zhihu", []):
            res = self.rss.search(category="zhihu")
            if isinstance(res, list): kb["zhihu"].extend(res)
            
        print("\nğŸ­ [æ•°æ®æ±‡æ€»] å®è§‚æ”¿ç­–+ä¸ªäººç—›ç‚¹+ä¸“å®¶äº‰è®º -> å¼€å§‹è·¨å¹³å°ç†”ç‚¼...")
        fact_pack = self._synthesize(topic, kb)
        print("âœ… =============== ç»ˆæä¸‰ç»´è°ƒç ”åŒ… (Triad Fact-Pack) ===============")
        print(fact_pack)
        print("=================================================================\n")
        return fact_pack

def test_cn_researcher():
    import sys
    sys.path.append("/root/.openclaw/workspace-writer/ai-article-publisher/core")
    from llm_client import ask_ai
    # æ¨¡æ‹Ÿä¸€æ¬¡å®æˆ˜å‘½é¢˜
    r = AutonomousResearcherCN(llm_callable=ask_ai)
    r.run("äººå·¥æ™ºèƒ½å¤§æ¨¡å‹å¯¹æ•™è‚²æ–‡ç§‘ä¸“ä¸šçš„å†²å‡»çœŸå®ç—›ç‚¹")

if __name__ == "__main__":
    test_cn_researcher()
