#!/usr/bin/env python3
"""
æ™ºèƒ½é€‰é¢˜é€‰æ‹©å™¨
ç»Ÿä¸€å…¥å£ï¼Œæ•´åˆåŸºç¡€è¯„åˆ† + è¶‹åŠ¿åˆ†æ + LLM åˆ†æ

âš ï¸ æˆæœ¬æ§åˆ¶é…ç½®
================
LLM è°ƒç”¨: OpenRouter DeepSeek R1 å…è´¹æ¨¡å‹
æ¨¡å‹: openrouter/deepseek/deepseek-r1-0528:free
è´¹ç”¨: $0 (å®Œå…¨å…è´¹)

è¶‹åŠ¿é¢„æµ‹: ç®€å•è§„åˆ™æ¨¡å‹ (æœ¬åœ°è®¡ç®—)
è´¹ç”¨: $0 (å®Œå…¨å…è´¹)

æ€»æˆæœ¬: $0

ä½œè€…: AI Article Publisher
åˆ›å»ºæ—¶é—´: 2026-02-22
"""

import json
import os
import sys
import argparse
from datetime import datetime
from typing import List, Dict, Any, Optional

# å¯¼å…¥å­æ¨¡å—
from topic_scorer import score_topic, rank_topics as base_rank
from trend_analyzer import analyze_topic_trend, batch_analyze_trends
from topic_analyzer import analyze_topic, rank_topics as llm_rank, OPENROUTER_API_KEY

# ============================================
# æˆæœ¬æ§åˆ¶é…ç½®
# ============================================
# æ‰€æœ‰ç»„ä»¶å‡å…è´¹

SELECTOR_CONFIG = {
    "name": "topic_selector",
    "version": "1.0.0",
    "components": {
        "base_scorer": {"model": "rules", "cost": "$0"},
        "trend_analyzer": {"model": "simple_rules", "cost": "$0"},
        "llm_analyzer": {"model": "step-3.5-flash-free", "cost": "$0"},
    },
    "total_cost": "$0",
    
    # æƒé‡é…ç½®
    "weights": {
        "base_score": 0.3,      # åŸºç¡€è¯„åˆ†æƒé‡
        "trend_score": 0.3,     # è¶‹åŠ¿è¯„åˆ†æƒé‡
        "llm_score": 0.4,       # LLM è¯„åˆ†æƒé‡
    },
}


def load_topics_from_file(filepath: str) -> List[Dict]:
    """ä»æ–‡ä»¶åŠ è½½é€‰é¢˜"""
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # æ”¯æŒå¤šç§æ ¼å¼
    if isinstance(data, dict):
        if "items" in data:
            return list(data["items"].values())
        else:
            return list(data.values())
    elif isinstance(data, list):
        return data
    else:
        return []


def calculate_final_score(
    base_score: float,
    trend_score: float,
    llm_score: float,
    weights: Dict = None,
) -> float:
    """
    è®¡ç®—æœ€ç»ˆç»¼åˆè¯„åˆ†
    
    å…¬å¼: final = base * w1 + trend * w2 + llm * w3
    """
    weights = weights or SELECTOR_CONFIG["weights"]
    
    # å½’ä¸€åŒ–åˆ° 0-100
    base_normalized = min(base_score, 100)
    trend_normalized = min(trend_score, 100)
    llm_normalized = min(llm_score, 100)
    
    final = (
        base_normalized * weights["base_score"] +
        trend_normalized * weights["trend_score"] +
        llm_normalized * weights["llm_score"]
    )
    
    return round(final, 1)


def select_topics(
    topics: List[Dict],
    user_profile: Dict = None,
    top_n: int = 10,
    use_llm: bool = True,
    verbose: bool = True,
) -> List[Dict]:
    """
    æ™ºèƒ½é€‰é¢˜é€‰æ‹©
    
    Args:
        topics: å€™é€‰é€‰é¢˜åˆ—è¡¨
        user_profile: ç”¨æˆ·ç”»åƒ
        top_n: è¿”å›æ•°é‡
        use_llm: æ˜¯å¦ä½¿ç”¨ LLM åˆ†æ
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        æ’åºåçš„é€‰é¢˜åˆ—è¡¨
    """
    if verbose:
        print(f"\n{'='*70}")
        print(f"æ™ºèƒ½é€‰é¢˜é€‰æ‹©å™¨ v{SELECTOR_CONFIG['version']}")
        print(f"{'='*70}")
        print(f"å€™é€‰é€‰é¢˜: {len(topics)} ä¸ª")
        print(f"è¿”å›æ•°é‡: {top_n} ä¸ª")
        print(f"ä½¿ç”¨ LLM: {'æ˜¯' if use_llm else 'å¦'}")
        print(f"")
        print(f"ç»„ä»¶é…ç½®:")
        print(f"  - åŸºç¡€è¯„åˆ†: {SELECTOR_CONFIG['components']['base_scorer']['model']} (å…è´¹)")
        print(f"  - è¶‹åŠ¿åˆ†æ: {SELECTOR_CONFIG['components']['trend_analyzer']['model']} (å…è´¹)")
        if use_llm:
            print(f"  - LLMåˆ†æ: {SELECTOR_CONFIG['components']['llm_analyzer']['model']} (å…è´¹)")
        print(f"æ€»æˆæœ¬: {SELECTOR_CONFIG['total_cost']}")
        print(f"{'='*70}\n")
    
    user_profile = user_profile or {
        "domains": ["æ•™è‚²", "å¿ƒç†å­¦", "AI"],
        "style": "æ·±åº¦åˆ†æ",
        "audience": "èŒåœºäººå£«",
    }
    
    results = []
    
    for i, topic in enumerate(topics[:top_n * 2]):
        title = topic.get("title", "æœªçŸ¥é€‰é¢˜")
        
        if verbose:
            print(f"[{i+1}/{min(len(topics), top_n*2)}] åˆ†æ: {title[:40]}...")
        
        # 1. åŸºç¡€è¯„åˆ†
        base_result = score_topic(topic, user_profile.get("domains", []))
        base_score = base_result.get("total", 50)
        
        if verbose:
            print(f"    åŸºç¡€è¯„åˆ†: {base_score}")
        
        # 2. è¶‹åŠ¿åˆ†æ
        trend_result = analyze_topic_trend(topic)
        trend_score = trend_result.get("trend_score", 50)
        
        if verbose:
            print(f"    è¶‹åŠ¿è¯„åˆ†: {trend_score} ({trend_result.get('direction', '')})")
        
        # 3. LLM åˆ†æ (å¯é€‰)
        llm_score = 50
        llm_result = None
        
        if use_llm:
            if OPENROUTER_API_KEY:
                llm_result = analyze_topic(topic, user_profile)
                if "error" not in llm_result:
                    llm_score = llm_result.get("overall_score", 50)
                    if verbose:
                        print(f"    LLMè¯„åˆ†: {llm_score} ({llm_result.get('recommendation', '')})")
                else:
                    if verbose:
                        print(f"    LLMåˆ†æ: å¤±è´¥ - {llm_result.get('error', '')}")
            else:
                if verbose:
                    print(f"    LLMåˆ†æ: è·³è¿‡ (æœªé…ç½® API Key)")
        
        # 4. ç»¼åˆè¯„åˆ†
        final_score = calculate_final_score(base_score, trend_score, llm_score)
        
        # æ¨èç­‰çº§
        if final_score >= 80:
            recommendation = "å¼ºçƒˆæ¨è"
        elif final_score >= 70:
            recommendation = "æ¨è"
        elif final_score >= 60:
            recommendation = "å¯ä»¥è€ƒè™‘"
        else:
            recommendation = "ä¸æ¨è"
        
        if verbose:
            print(f"    âœ… ç»¼åˆè¯„åˆ†: {final_score} ({recommendation})")
            print()
        
        # ç»„è£…ç»“æœ
        result = {
            "title": title,
            "url": topic.get("url", ""),
            "source": topic.get("source", ""),
            "category": topic.get("category", ""),
            
            # è¯„åˆ†
            "final_score": final_score,
            "recommendation": recommendation,
            
            # åˆ†é¡¹è¯„åˆ†
            "scores": {
                "base": base_score,
                "trend": trend_score,
                "llm": llm_score if use_llm else None,
            },
            
            # è¶‹åŠ¿ä¿¡æ¯
            "trend": {
                "direction": trend_result.get("direction", ""),
                "lifecycle": trend_result.get("lifecycle", ""),
                "best_timing": trend_result.get("best_timing", ""),
            },
            
            # LLM åˆ†æç»“æœ
            "llm_analysis": llm_result,
            
            # åŸå§‹æ•°æ®
            "raw": topic,
        }
        
        results.append(result)
    
    # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
    results.sort(key=lambda x: x["final_score"], reverse=True)
    
    return results[:top_n]


def generate_final_report(results: List[Dict], output_format: str = "text") -> str:
    """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
    
    if output_format == "json":
        return json.dumps(results, ensure_ascii=False, indent=2)
    
    # æ–‡æœ¬æŠ¥å‘Š
    lines = [
        "=" * 70,
        "æ™ºèƒ½é€‰é¢˜æ¨èæŠ¥å‘Š",
        f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        "=" * 70,
        "",
    ]
    
    # ç»Ÿè®¡
    strong_rec = [r for r in results if r["final_score"] >= 80]
    rec = [r for r in results if 70 <= r["final_score"] < 80]
    consider = [r for r in results if 60 <= r["final_score"] < 70]
    
    lines.append(f"ğŸ“Š æ¨èç»Ÿè®¡:")
    lines.append(f"  - å¼ºçƒˆæ¨è (80+): {len(strong_rec)} ä¸ª")
    lines.append(f"  - æ¨è (70+): {len(rec)} ä¸ª")
    lines.append(f"  - å¯ä»¥è€ƒè™‘ (60+): {len(consider)} ä¸ª")
    lines.append("")
    lines.append("-" * 70)
    lines.append("")
    
    for i, result in enumerate(results, 1):
        score_emoji = "ğŸ”¥" if result["final_score"] >= 80 else "âœ…" if result["final_score"] >= 70 else "ğŸ’¡"
        
        lines.append(f"{score_emoji} ã€{i}ã€‘{result['title']}")
        lines.append(f"    æ¥æº: {result['source']} | åˆ†ç±»: {result['category']}")
        lines.append(f"    ç»¼åˆè¯„åˆ†: {result['final_score']} ({result['recommendation']})")
        lines.append(f"    åˆ†é¡¹: åŸºç¡€{result['scores']['base']:.0f} + "
                    f"è¶‹åŠ¿{result['scores']['trend']:.0f}" +
                    (f" + LLM{result['scores']['llm']:.0f}" if result['scores']['llm'] else ""))
        
        trend = result.get("trend", {})
        if trend:
            lines.append(f"    è¶‹åŠ¿: {trend.get('direction', '')} | {trend.get('lifecycle', '')}")
            lines.append(f"    å‘å¸ƒå»ºè®®: {trend.get('best_timing', '')}")
        
        llm = result.get("llm_analysis", {})
        if llm and "writing_angles" in llm:
            angles = llm["writing_angles"][:2]
            lines.append("    å†™ä½œè§’åº¦:")
            for angle in angles:
                lines.append(f"      - {angle.get('angle', '')}: {angle.get('title', '')}")
        
        lines.append("")
    
    lines.extend([
        "=" * 70,
        "æˆæœ¬è¯´æ˜:",
        f"- åŸºç¡€è¯„åˆ†: $0 (æœ¬åœ°è§„åˆ™)",
        f"- è¶‹åŠ¿åˆ†æ: $0 (æœ¬åœ°è®¡ç®—)",
        f"- LLMåˆ†æ: $0 (DeepSeek R1 å…è´¹æ¨¡å‹)",
        f"- æ€»æˆæœ¬: $0",
        "",
        "è¯„åˆ†æƒé‡:",
        f"- åŸºç¡€è¯„åˆ†: {SELECTOR_CONFIG['weights']['base_score']*100}%",
        f"- è¶‹åŠ¿è¯„åˆ†: {SELECTOR_CONFIG['weights']['trend_score']*100}%",
        f"- LLMè¯„åˆ†: {SELECTOR_CONFIG['weights']['llm_score']*100}%",
        "=" * 70,
    ])
    
    return "\n".join(lines)


def main():
    parser = argparse.ArgumentParser(description='æ™ºèƒ½é€‰é¢˜é€‰æ‹©å™¨')
    parser.add_argument('--input', '-i', help='è¾“å…¥JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', default='text', choices=['text', 'json'], help='è¾“å‡ºæ ¼å¼')
    parser.add_argument('--top', '-n', type=int, default=5, help='è¾“å‡ºæ•°é‡')
    parser.add_argument('--domains', '-d', default='æ•™è‚²,å¿ƒç†å­¦,AI', help='ç”¨æˆ·å…³æ³¨é¢†åŸŸ')
    parser.add_argument('--no-llm', action='store_true', help='ä¸ä½¿ç”¨LLMåˆ†æ')
    parser.add_argument('--quiet', '-q', action='store_true', help='å®‰é™æ¨¡å¼')
    args = parser.parse_args()
    
    # ç”¨æˆ·ç”»åƒ
    user_profile = {
        "domains": [d.strip() for d in args.domains.split(',')],
        "style": "æ·±åº¦åˆ†æ",
        "audience": "èŒåœºäººå£«",
    }
    
    # åŠ è½½é€‰é¢˜
    if args.input:
        topics = load_topics_from_file(args.input)
    else:
        # ç¤ºä¾‹æ•°æ®
        topics = [
            {"title": "AI ç¼–ç¨‹åŠ©æ‰‹å¯¹æ¯”ï¼šClaude vs GPT-4", "source": "å°‘æ•°æ´¾", "score": "10ä¸‡é˜…è¯»", "category": "ç§‘æŠ€"},
            {"title": "å¿ƒç†å­¦ç ”ç©¶ï¼šå‹åŠ›ä¸è®¤çŸ¥çš„å…³ç³»", "source": "ScienceDaily", "score": "é«˜çƒ­åº¦", "category": "å¿ƒç†å­¦"},
            {"title": "å¦‚ä½•æé«˜å­¦ä¹ æ•ˆç‡ï¼Ÿ5ä¸ªå®ç”¨æ–¹æ³•", "source": "çŸ¥ä¹", "score": "5000èµåŒ", "category": "æ•™è‚²"},
        ]
    
    # é€‰æ‹©é€‰é¢˜
    results = select_topics(
        topics,
        user_profile,
        top_n=args.top,
        use_llm=not args.no_llm,
        verbose=not args.quiet,
    )
    
    # è¾“å‡ºæŠ¥å‘Š
    report = generate_final_report(results, args.output)
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    if args.input:
        output_file = args.input.replace('.json', '_selected.json')
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {output_file}")


if __name__ == '__main__':
    main()