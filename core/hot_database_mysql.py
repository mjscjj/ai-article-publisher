#!/usr/bin/env python3
"""
ã€çƒ­ç‚¹æ•°æ®åº“ - MySQL ç‰ˆæœ¬ã€‘Hot News Database (MySQL)
åŸºäº MySQL çš„çƒ­ç‚¹æ•°æ®å­˜å‚¨ä¸ç®¡ç†

æ•°æ®åº“è¿æ¥:
- ä¸»æœºï¼š43.134.234.4 (localhost)
- ç«¯å£ï¼š3306
- æ•°æ®åº“ï¼šyoumind
- ç”¨æˆ·ï¼šyoumind
- å¯†ç ï¼šYouMind2026
"""

import os
import sys
import json
import hashlib
import re
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from collections import Counter

# å°è¯•å¯¼å…¥ pymysql
try:
    import pymysql
    MYSQL_AVAILABLE = True
except ImportError:
    MYSQL_AVAILABLE = False
    print("âš ï¸  pymysql æœªå®‰è£…ï¼Œè¯·è¿è¡Œï¼špip install pymysql")

class HotNewsDatabaseMySQL:
    """çƒ­ç‚¹æ•°æ®åº“ (MySQL ç‰ˆæœ¬)"""
    
    def __init__(self, 
                 host: str = "43.134.234.4",
                 port: int = 3306,
                 database: str = "youmind",
                 user: str = "youmind",
                 password: str = "YouMind2026"):
        """
        Args:
            host: æ•°æ®åº“ä¸»æœº
            port: ç«¯å£
            database: æ•°æ®åº“å
            user: ç”¨æˆ·å
            password: å¯†ç 
        """
        if not MYSQL_AVAILABLE:
            raise ImportError("pymysql æœªå®‰è£…")
        
        self.config = {
            'host': host,
            'port': port,
            'database': database,
            'user': user,
            'password': password,
            'charset': 'utf8mb4',
            'cursorclass': pymysql.cursors.DictCursor
        }
        
        self.conn = None
        self._connect()
        self._init_tables()
    
    def _connect(self):
        """å»ºç«‹æ•°æ®åº“è¿æ¥"""
        try:
            self.conn = pymysql.connect(**self.config)
            print(f"[MySQL] âœ… è¿æ¥æˆåŠŸï¼š{self.config['host']}:{self.config['port']}/{self.config['database']}")
        except Exception as e:
            print(f"[MySQL] âŒ è¿æ¥å¤±è´¥ï¼š{e}")
            raise
    
    def _execute(self, query: str, params: tuple = None):
        """æ‰§è¡Œ SQL è¯­å¥"""
        cursor = self.conn.cursor()
        try:
            cursor.execute(query, params or ())
            self.conn.commit()
            return cursor
        except Exception as e:
            self.conn.rollback()
            print(f"[MySQL] âŒ SQL é”™è¯¯ï¼š{e}")
            raise
        finally:
            cursor.close()
    
    def _fetch_all(self, query: str, params: tuple = None) -> List[Dict]:
        """æŸ¥è¯¢å¹¶è¿”å›æ‰€æœ‰ç»“æœ"""
        cursor = self.conn.cursor()
        try:
            cursor.execute(query, params or ())
            return cursor.fetchall()
        finally:
            cursor.close()
    
    def _fetch_one(self, query: str, params: tuple = None) -> Optional[Dict]:
        """æŸ¥è¯¢å¹¶è¿”å›å•æ¡ç»“æœ"""
        cursor = self.conn.cursor()
        try:
            cursor.execute(query, params or ())
            return cursor.fetchone()
        finally:
            cursor.close()
    
    def _init_tables(self):
        """åˆå§‹åŒ–æ•°æ®è¡¨"""
        # 1. çƒ­ç‚¹ä¸»è¡¨
        self._execute('''
            CREATE TABLE IF NOT EXISTS hot_topics (
                id INT AUTO_INCREMENT PRIMARY KEY,
                title VARCHAR(500) NOT NULL,
                content TEXT,
                url VARCHAR(1000),
                source_id INT,
                crawl_date DATE NOT NULL,
                crawl_time DATETIME NOT NULL,
                publish_time DATETIME,
                heat_score DECIMAL(5,2) DEFAULT 0,
                heat_level VARCHAR(20) DEFAULT 'normal',
                category VARCHAR(50),
                tags JSON,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                INDEX idx_crawl_date (crawl_date),
                INDEX idx_crawl_time (crawl_time),
                INDEX idx_heat (heat_score),
                INDEX idx_category (category)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        ''')
        
        # 2. æ¥æºè¡¨
        self._execute('''
            CREATE TABLE IF NOT EXISTS hot_sources (
                id INT AUTO_INCREMENT PRIMARY KEY,
                name VARCHAR(100) NOT NULL UNIQUE,
                platform VARCHAR(50),
                category VARCHAR(50),
                base_url VARCHAR(500),
                priority INT DEFAULT 5,
                credibility DECIMAL(3,2) DEFAULT 0.5,
                is_active TINYINT DEFAULT 1,
                last_crawl DATETIME,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_platform (platform),
                INDEX idx_category (category)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        ''')
        
        # 3. å…³é”®è¯è¡¨
        self._execute('''
            CREATE TABLE IF NOT EXISTS hot_keywords (
                id INT AUTO_INCREMENT PRIMARY KEY,
                topic_id INT NOT NULL,
                keyword VARCHAR(100) NOT NULL,
                weight DECIMAL(5,2) DEFAULT 1.0,
                category VARCHAR(50),
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_topic (topic_id),
                INDEX idx_keyword (keyword),
                FOREIGN KEY (topic_id) REFERENCES hot_topics(id) ON DELETE CASCADE
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        ''')
        
        # 4. ç»Ÿè®¡è¡¨
        self._execute('''
            CREATE TABLE IF NOT EXISTS hot_statistics (
                id INT AUTO_INCREMENT PRIMARY KEY,
                stat_date DATE NOT NULL,
                category VARCHAR(50),
                source_id INT,
                total_count INT DEFAULT 0,
                avg_heat_score DECIMAL(5,2) DEFAULT 0,
                max_heat_score DECIMAL(5,2) DEFAULT 0,
                unique_count INT DEFAULT 0,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uk_date_category_source (stat_date, category, source_id),
                INDEX idx_date (stat_date)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
        ''')
        
        print(f"[MySQL] âœ… æ•°æ®è¡¨åˆå§‹åŒ–æˆåŠŸ")
    
    # ========== æ¥æºç®¡ç† ==========
    
    def add_source(self, name: str, platform: str = None, 
                   category: str = None, base_url: str = None,
                   priority: int = 5, credibility: float = 0.5) -> int:
        """æ·»åŠ æ•°æ®æº"""
        self._execute('''
            INSERT INTO hot_sources (name, platform, category, base_url, priority, credibility)
            VALUES (%s, %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE 
                platform=VALUES(platform),
                category=VALUES(category),
                priority=VALUES(priority),
                credibility=VALUES(credibility)
        ''', (name, platform, category, base_url, priority, credibility))
        
        result = self._fetch_one('SELECT id FROM hot_sources WHERE name = %s', (name,))
        print(f"[MySQL] âœ… æ·»åŠ æ•°æ®æºï¼š{name} (ID: {result['id']})")
        return result['id']
    
    def get_sources(self, category: str = None, active_only: bool = True) -> List[Dict]:
        """è·å–æ•°æ®æºåˆ—è¡¨"""
        query = 'SELECT * FROM hot_sources'
        params = []
        
        if active_only:
            query += ' WHERE is_active = 1'
        
        if category:
            query += ' AND category = %s' if active_only else ' WHERE category = %s'
            params.append(category)
        
        query += ' ORDER BY priority DESC, credibility DESC'
        
        return self._fetch_all(query, tuple(params))
    
    # ========== çƒ­ç‚¹å­˜å‚¨ ==========
    
    def add_hot_topic(self, title: str, content: str = None,
                     url: str = None, source_name: str = None,
                     crawl_time: datetime = None, publish_time: datetime = None,
                     heat_score: float = None, category: str = None,
                     tags: List[str] = None, keywords: List[str] = None) -> int:
        """æ·»åŠ çƒ­ç‚¹"""
        # 1. è·å–æˆ–åˆ›å»ºæ¥æº
        source_id = self._get_or_create_source(source_name)
        
        # 2. è®¾ç½®é»˜è®¤å€¼
        if crawl_time is None:
            crawl_time = datetime.now()
        if heat_score is None:
            heat_score = self._calculate_heat_score(title, content, source_name)
        
        # 3. æ’å…¥æ•°æ®åº“
        crawl_date = crawl_time.date() if hasattr(crawl_time, 'date') else crawl_time.date()
        
        self._execute('''
            INSERT INTO hot_topics 
            (title, content, url, source_id, crawl_date, crawl_time, publish_time, 
             heat_score, heat_level, category, tags)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        ''', (
            title, content, url, source_id,
            crawl_date, crawl_time, publish_time,
            heat_score,
            self._get_heat_level(heat_score),
            category,
            json.dumps(tags, ensure_ascii=False) if tags else None
        ))
        
        topic_id = self._fetch_one('SELECT LAST_INSERT_ID() as id')['id']
        
        # 4. æ·»åŠ å…³é”®è¯
        if keywords:
            self._add_keywords(topic_id, keywords)
        
        print(f"[MySQL] âœ… æ·»åŠ çƒ­ç‚¹ï¼š{title[:30]}... (ID: {topic_id}, çƒ­åº¦ï¼š{heat_score})")
        return topic_id
    
    def _get_or_create_source(self, source_name: str) -> int:
        """è·å–æˆ–åˆ›å»ºæ¥æº"""
        if not source_name:
            return 1
        
        result = self._fetch_one('SELECT id FROM hot_sources WHERE name = %s', (source_name,))
        if result:
            return result['id']
        
        return self.add_source(source_name)
    
    def _calculate_heat_score(self, title: str, content: str = None,
                             source_name: str = None) -> float:
        """è®¡ç®—çƒ­åº¦å€¼"""
        score = 50.0
        
        title_len = len(title)
        if 20 <= title_len <= 40:
            score += 10
        elif 10 <= title_len < 20 or 40 < title_len <= 60:
            score += 5
        
        source_credibility = self._get_source_credibility(source_name)
        score += source_credibility * 20
        
        if content:
            content_len = len(content)
            if 100 <= content_len <= 500:
                score += 10
            elif content_len > 500:
                score += 5
        
        hot_keywords = ['çªå‘', 'é‡ç£…', 'æœ€æ–°', 'åˆšåˆš', 'éœ‡æƒŠ', 'æ›å…‰']
        if any(kw in title for kw in hot_keywords):
            score += 5
        
        return min(100, max(0, score))
    
    def _get_source_credibility(self, source_name: str) -> float:
        """è·å–æ¥æºå¯ä¿¡åº¦"""
        if not source_name:
            return 0.5
        
        result = self._fetch_one('SELECT credibility FROM hot_sources WHERE name = %s', (source_name,))
        return float(result['credibility']) if result else 0.5
    
    def _get_heat_level(self, heat_score: float) -> str:
        """è·å–çƒ­åº¦ç­‰çº§"""
        if heat_score >= 90:
            return 'explosive'
        elif heat_score >= 75:
            return 'hot'
        elif heat_score >= 60:
            return 'warm'
        else:
            return 'normal'
    
    def _add_keywords(self, topic_id: int, keywords: List[str]):
        """æ·»åŠ å…³é”®è¯"""
        for keyword in keywords:
            self._execute('''
                INSERT INTO hot_keywords (topic_id, keyword, weight)
                VALUES (%s, %s, %s)
            ''', (topic_id, keyword, 1.0))
    
    # ========== çƒ­ç‚¹æŸ¥è¯¢ ==========
    
    def get_hot_topics(self, limit: int = 20, 
                      category: str = None,
                      heat_level: str = None,
                      source_name: str = None,
                      time_range_hours: int = None,
                      crawl_date: str = None) -> List[Dict]:
        """
        è·å–çƒ­ç‚¹åˆ—è¡¨
        
        Args:
            limit: è¿”å›æ•°é‡
            category: åˆ†ç±»è¿‡æ»¤
            heat_level: çƒ­åº¦ç­‰çº§
            source_name: æ¥æºè¿‡æ»¤
            time_range_hours: æ—¶é—´èŒƒå›´ (å°æ—¶)
            crawl_date: é‡‡é›†æ—¥æœŸ (æ ¼å¼ï¼š'2026-03-01' æˆ– 'today' æˆ– 'yesterday')
        """
        query = '''
            SELECT t.*, s.name as source_name, s.platform, s.category as source_category
            FROM hot_topics t
            LEFT JOIN hot_sources s ON t.source_id = s.id
            WHERE 1=1
        '''
        params = []
        
        if category:
            query += ' AND (t.category = %s OR s.category = %s)'
            params.extend([category, category])
        
        if heat_level:
            query += ' AND t.heat_level = %s'
            params.append(heat_level)
        
        if source_name:
            query += ' AND s.name = %s'
            params.append(source_name)
        
        if crawl_date:
            if crawl_date == 'today':
                crawl_date = datetime.now().date().isoformat()
            elif crawl_date == 'yesterday':
                crawl_date = (datetime.now() - timedelta(days=1)).date().isoformat()
            query += ' AND t.crawl_date = %s'
            params.append(crawl_date)
        elif time_range_hours:
            time_threshold = datetime.now() - timedelta(hours=time_range_hours)
            query += ' AND t.crawl_time > %s'
            params.append(time_threshold)
        
        query += ' ORDER BY t.heat_score DESC, t.crawl_time DESC'
        query += ' LIMIT %s'
        params.append(limit)
        
        results = self._fetch_all(query, tuple(params))
        
        # è§£æ JSON å­—æ®µ
        for item in results:
            if item.get('tags') and isinstance(item['tags'], str):
                try:
                    item['tags'] = json.loads(item['tags'])
                except:
                    item['tags'] = []
        
        return results
    
    def get_keywords_by_topic(self, topic_id: int) -> List[Dict]:
        """è·å–çƒ­ç‚¹çš„å…³é”®è¯"""
        return self._fetch_all('''
            SELECT * FROM hot_keywords 
            WHERE topic_id = %s 
            ORDER BY weight DESC
        ''', (topic_id,))
    
    # ========== ç»Ÿè®¡åˆ†æ ==========
    
    def get_statistics(self, days: int = 7) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡æ•°æ®"""
        time_threshold = datetime.now() - timedelta(days=days)
        
        # æ€»ä½“ç»Ÿè®¡
        overall = self._fetch_one('''
            SELECT 
                COUNT(*) as total_count,
                AVG(heat_score) as avg_heat,
                MAX(heat_score) as max_heat,
                COUNT(DISTINCT keyword_hash) as unique_count
            FROM hot_topics
            WHERE crawl_time > %s
        ''', (time_threshold,))
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        by_category = self._fetch_all('''
            SELECT category, COUNT(*) as count, AVG(heat_score) as avg_heat
            FROM hot_topics
            WHERE crawl_time > %s AND category IS NOT NULL
            GROUP BY category
            ORDER BY count DESC
        ''', (time_threshold,))
        
        # æŒ‰æ¥æºç»Ÿè®¡
        by_source = self._fetch_all('''
            SELECT s.name, s.platform, COUNT(t.id) as count, AVG(t.heat_score) as avg_heat
            FROM hot_topics t
            LEFT JOIN hot_sources s ON t.source_id = s.id
            WHERE t.crawl_time > %s
            GROUP BY s.name, s.platform
            ORDER BY count DESC
            LIMIT 20
        ''', (time_threshold,))
        
        # çƒ­è¯ç»Ÿè®¡
        hot_keywords = self._fetch_all('''
            SELECT k.keyword, COUNT(*) as count, AVG(k.weight) as avg_weight
            FROM hot_keywords k
            INNER JOIN hot_topics t ON k.topic_id = t.id
            WHERE t.crawl_time > %s
            GROUP BY k.keyword
            ORDER BY count DESC
            LIMIT 50
        ''', (time_threshold,))
        
        return {
            'overall': overall,
            'by_category': by_category,
            'by_source': by_source,
            'hot_keywords': hot_keywords,
            'time_range': f'{days} days'
        }
    
    # ========== æ•°æ®æ¸…ç† ==========
    
    def cleanup_old_data(self, days_to_keep: int = 30) -> int:
        """æ¸…ç†æ—§æ•°æ®"""
        date_threshold = datetime.now().date() - timedelta(days=days_to_keep)
        
        result = self._execute('DELETE FROM hot_topics WHERE crawl_date < %s', (date_threshold,))
        deleted = result.rowcount
        
        print(f"[MySQL] âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤ {deleted} æ¡æ—§çƒ­ç‚¹")
        return deleted
    
    def get_date_range(self) -> Dict[str, str]:
        """è·å–æ•°æ®æ—¥æœŸèŒƒå›´"""
        result = self._fetch_one('''
            SELECT 
                MIN(crawl_date) as earliest_date,
                MAX(crawl_date) as latest_date,
                COUNT(DISTINCT crawl_date) as date_count
            FROM hot_topics
        ''')
        return result if result else {}
    
    def get_available_dates(self, limit: int = 30) -> List[str]:
        """è·å–å¯ç”¨çš„æ—¥æœŸåˆ—è¡¨"""
        results = self._fetch_all('''
            SELECT DISTINCT crawl_date
            FROM hot_topics
            ORDER BY crawl_date DESC
            LIMIT %s
        ''', (limit,))
        return [str(r['crawl_date']) for r in results]
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()
            print("[MySQL] âœ… è¿æ¥å·²å…³é—­")


# ========== ä¾¿æ·å‡½æ•° ==========

def get_hot_db_mysql() -> HotNewsDatabaseMySQL:
    """è·å–æ•°æ®åº“å®ä¾‹"""
    return HotNewsDatabaseMySQL()


def test_mysql_database():
    """æµ‹è¯•æ•°æ®åº“"""
    print("\n" + "="*70)
    print("ğŸ—„ï¸  çƒ­ç‚¹æ•°æ®åº“ MySQL æµ‹è¯•")
    print("="*70 + "\n")
    
    db = get_hot_db_mysql()
    
    # 1. æ·»åŠ æ•°æ®æº
    print("Step 1: æ·»åŠ æ•°æ®æº")
    db.add_source("å¾®åšçƒ­æœ", platform="å¾®åš", category="ç»¼åˆ", priority=10, credibility=0.8)
    db.add_source("çŸ¥ä¹çƒ­æ¦œ", platform="çŸ¥ä¹", category="ç»¼åˆ", priority=9, credibility=0.85)
    db.add_source("æ¾æ¹ƒæ–°é—»", platform="æ¾æ¹ƒæ–°é—»", category="æ–°é—»", priority=8, credibility=0.9)
    
    # 2. æ·»åŠ çƒ­ç‚¹
    print("\nStep 2: æ·»åŠ çƒ­ç‚¹")
    db.add_hot_topic(
        title="æ•™è‚²éƒ¨å‘å¸ƒ AI+ æ•™è‚²æŒ‡å¯¼æ„è§ï¼Œ60% é«˜æ ¡å·²å¼€è®¾ç›¸å…³è¯¾ç¨‹",
        content="æ•™è‚²éƒ¨è¿‘æ—¥å‘å¸ƒã€Šäººå·¥æ™ºèƒ½ + æ•™è‚²ã€‹æŒ‡å¯¼æ„è§ï¼Œæå‡ºåˆ° 2025 å¹´...",
        url="https://example.com/news/123",
        source_name="æ¾æ¹ƒæ–°é—»",
        category="æ•™è‚²",
        tags=["AI", "æ•™è‚²", "æ”¿ç­–"],
        keywords=["æ•™è‚²éƒ¨", "AI æ•™è‚²", "é«˜æ ¡è¯¾ç¨‹"]
    )
    
    db.add_hot_topic(
        title="AI ç¨‹åºå‘˜å¤±ä¸šæ½®æ¥äº†ï¼Ÿä¸“å®¶ï¼šä¸ä¼šç”¨ AI çš„æ‰ä¼šè¢«æ·˜æ±°",
        content="è¿‘æ—¥ï¼ŒæŸå¤§å‚å®£å¸ƒè£å‘˜ 30%ï¼Œå…¶ä¸­ç¨‹åºå‘˜å æ¯”æœ€é«˜...",
        url="https://example.com/news/124",
        source_name="çŸ¥ä¹çƒ­æ¦œ",
        category="ç§‘æŠ€",
        tags=["AI", "å°±ä¸š", "ç¨‹åºå‘˜"],
        keywords=["AI", "ç¨‹åºå‘˜", "å¤±ä¸š", "è£å‘˜"]
    )
    
    # 3. æŸ¥è¯¢çƒ­ç‚¹
    print("\nStep 3: æŸ¥è¯¢çƒ­ç‚¹")
    topics = db.get_hot_topics(limit=5)
    for i, t in enumerate(topics, 1):
        print(f"  {i}. [{t['heat_level']}] {t['title'][:40]}...")
        print(f"     æ¥æºï¼š{t['source_name']} | çƒ­åº¦ï¼š{float(t['heat_score']):.1f}")
    
    # 4. ç»Ÿè®¡
    print("\nStep 4: ç»Ÿè®¡æ•°æ®")
    stats = db.get_statistics(days=7)
    print(f"  æ€»çƒ­ç‚¹æ•°ï¼š{stats['overall']['total_count']}")
    print(f"  å¹³å‡çƒ­åº¦ï¼š{float(stats['overall']['avg_heat']):.1f}")
    print(f"  å”¯ä¸€çƒ­ç‚¹ï¼š{stats['overall']['unique_count']}")
    
    db.close()
    
    print("\n" + "="*70)
    print("ğŸ‰ MySQL æ•°æ®åº“æµ‹è¯•å®Œæˆ")
    print("="*70 + "\n")


if __name__ == "__main__":
    test_mysql_database()
