#!/usr/bin/env python3
"""
ã€çƒ­ç‚¹é‡‡é›†å™¨ V2ã€‘Hot News Collector V2
åŸºäºæ–°æ•°æ®åº“æ¶æ„é‡æ„çš„çƒ­ç‚¹é‡‡é›†æ¨¡å—

å¤ç”¨å·²æœ‰èƒ½åŠ›:
1. DailyHotApi é‡‡é›†å™¨ (sources/dailyhot_collector.py)
2. RSSHub é‡‡é›†å™¨ (sources/extended_collectors_v2.py)
3. è§†é¢‘é‡‡é›†å™¨ (sources/video_collector.py)
4. å†…å®¹é‡‡é›†å™¨ (sources/content_collector.py)
5. å‚ç›´é¢†åŸŸé‡‡é›†å™¨ (sources/vertical_collector.py)

æ–°å¢åŠŸèƒ½:
1. æ•°æ®åº“å­˜å‚¨ (hot_database.py)
2. æ™ºèƒ½å»é‡ (åŸºäºå…³é”®è¯å“ˆå¸Œ)
3. çƒ­åº¦è®¡ç®— (å¤šç»´æƒé‡è¯„åˆ†)
4. è‡ªåŠ¨åˆ†ç±» (åŸºäºæ¥æºå’Œå…³é”®è¯)
5. ç»Ÿè®¡åˆ†æ (å¤šç»´åº¦æŠ¥è¡¨)
"""

import os
import sys
import json
from datetime import datetime
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, PROJECT_ROOT)
sys.path.insert(0, os.path.join(PROJECT_ROOT, 'sources'))

# å¯¼å…¥æ•°æ®åº“
from core.hot_database import HotNewsDatabase

# å¯¼å…¥å·²æœ‰é‡‡é›†å™¨
try:
    from sources.dailyhot_collector import collect_all_platforms as collect_dailyhot
    DAILYHOT_AVAILABLE = True
except ImportError:
    DAILYHOT_AVAILABLE = False
    print("âš ï¸  DailyHotApi é‡‡é›†å™¨ä¸å¯ç”¨")

try:
    from sources.extended_collectors_v2 import collect_all_sources as collect_rsshub
    RSSHUB_AVAILABLE = True
except ImportError:
    RSSHUB_AVAILABLE = False
    print("âš ï¸  RSSHub é‡‡é›†å™¨ä¸å¯ç”¨")

try:
    from sources.video_collector import collect_all_platforms as collect_videos
    VIDEO_AVAILABLE = True
except ImportError:
    VIDEO_AVAILABLE = False
    print("âš ï¸  è§†é¢‘é‡‡é›†å™¨ä¸å¯ç”¨")


class HotNewsCollectorV2:
    """çƒ­ç‚¹é‡‡é›†å™¨ V2"""
    
    def __init__(self, db_path: str = None):
        """
        Args:
            db_path: æ•°æ®åº“è·¯å¾„ (å¯é€‰)
        """
        self.db = HotNewsDatabase(db_path)
        self.stats = {
            'total_collected': 0,
            'total_stored': 0,
            'duplicates': 0,
            'errors': 0
        }
        
        # åˆå§‹åŒ–æ•°æ®æº
        self._init_sources()
    
    def _init_sources(self):
        """åˆå§‹åŒ–æ•°æ®æºé…ç½®"""
        sources = [
            # DailyHotApi æ¥æº
            {"name": "å¾®åšçƒ­æœ", "platform": "å¾®åš", "category": "ç»¼åˆ", "priority": 10, "credibility": 0.8},
            {"name": "çŸ¥ä¹çƒ­æ¦œ", "platform": "çŸ¥ä¹", "category": "ç»¼åˆ", "priority": 9, "credibility": 0.85},
            {"name": "ç™¾åº¦çƒ­æ¦œ", "platform": "ç™¾åº¦", "category": "ç»¼åˆ", "priority": 8, "credibility": 0.7},
            {"name": "æŠ–éŸ³çƒ­ç‚¹", "platform": "æŠ–éŸ³", "category": "è§†é¢‘", "priority": 9, "credibility": 0.75},
            {"name": "B ç«™çƒ­é—¨", "platform": "B ç«™", "category": "è§†é¢‘", "priority": 8, "credibility": 0.8},
            
            # RSSHub æ¥æº
            {"name": "æ¾æ¹ƒæ–°é—»", "platform": "æ¾æ¹ƒæ–°é—»", "category": "æ–°é—»", "priority": 8, "credibility": 0.9},
            {"name": "36 æ°ª", "platform": "36 æ°ª", "category": "è´¢ç»", "priority": 7, "credibility": 0.85},
            {"name": "è™å—…", "platform": "è™å—…", "category": "è´¢ç»", "priority": 7, "credibility": 0.8},
            {"name": "IT ä¹‹å®¶", "platform": "IT ä¹‹å®¶", "category": "ç§‘æŠ€", "priority": 7, "credibility": 0.75},
            {"name": "å°‘æ•°æ´¾", "platform": "å°‘æ•°æ´¾", "category": "ç§‘æŠ€", "priority": 6, "credibility": 0.8},
        ]
        
        for source in sources:
            self.db.add_source(**source)
        
        print(f"[Collector] âœ… åˆå§‹åŒ– {len(sources)} ä¸ªæ•°æ®æº")
    
    def collect_all(self, save_to_db: bool = True) -> Dict[str, Any]:
        """
        é‡‡é›†æ‰€æœ‰æ•°æ®æº
        
        Args:
            save_to_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“
        
        Returns:
            é‡‡é›†ç»“æœç»Ÿè®¡
        """
        print(f"\n{'='*70}")
        print("ğŸ“¡ å¼€å§‹é‡‡é›†çƒ­ç‚¹æ•°æ®")
        print(f"{'='*70}\n")
        
        start_time = datetime.now()
        
        # 1. DailyHotApi é‡‡é›†
        if DAILYHOT_AVAILABLE:
            print("Step 1: DailyHotApi é‡‡é›†")
            dailyhot_result = self._collect_dailyhot()
            print(f"   âœ… é‡‡é›† {dailyhot_result['count']} æ¡\n")
        else:
            dailyhot_result = {"count": 0, "items": []}
        
        # 2. RSSHub é‡‡é›†
        if RSSHUB_AVAILABLE:
            print("Step 2: RSSHub é‡‡é›†")
            rsshub_result = self._collect_rsshub()
            print(f"   âœ… é‡‡é›† {rsshub_result['count']} æ¡\n")
        else:
            rsshub_result = {"count": 0, "items": []}
        
        # 3. è§†é¢‘é‡‡é›†
        if VIDEO_AVAILABLE:
            print("Step 3: è§†é¢‘é‡‡é›†")
            video_result = self._collect_videos()
            print(f"   âœ… é‡‡é›† {video_result['count']} æ¡\n")
        else:
            video_result = {"count": 0, "items": []}
        
        # 4. åˆå¹¶ç»“æœ
        all_items = (
            dailyhot_result.get('items', []) +
            rsshub_result.get('items', []) +
            video_result.get('items', [])
        )
        
        self.stats['total_collected'] = len(all_items)
        
        # 5. ä¿å­˜åˆ°æ•°æ®åº“
        if save_to_db:
            print("Step 4: ä¿å­˜åˆ°æ•°æ®åº“")
            store_result = self._save_to_database(all_items)
            print(f"   âœ… å­˜å‚¨ {store_result['stored']} æ¡ï¼Œè·³è¿‡ {store_result['skipped']} æ¡ (é‡å¤)\n")
        
        # 6. ç”ŸæˆæŠ¥å‘Š
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        report = {
            'start_time': start_time.isoformat(),
            'end_time': end_time.isoformat(),
            'duration_seconds': duration,
            'total_collected': self.stats['total_collected'],
            'total_stored': self.stats['total_stored'],
            'duplicates': self.stats['duplicates'],
            'errors': self.stats['errors'],
            'by_source': {
                'dailyhot': dailyhot_result.get('count', 0),
                'rsshub': rsshub_result.get('count', 0),
                'video': video_result.get('count', 0)
            }
        }
        
        print(f"{'='*70}")
        print("ğŸ“Š é‡‡é›†å®Œæˆ")
        print(f"  æ€»é‡‡é›†ï¼š{report['total_collected']} æ¡")
        print(f"  æ€»å­˜å‚¨ï¼š{report['total_stored']} æ¡")
        print(f"  é‡å¤è·³è¿‡ï¼š{report['duplicates']} æ¡")
        print(f"  è€—æ—¶ï¼š{duration:.2f}ç§’")
        print(f"{'='*70}\n")
        
        return report
    
    def _collect_dailyhot(self) -> Dict[str, Any]:
        """é‡‡é›† DailyHotApi"""
        try:
            result = collect_dailyhot()
            items = result.get('items', [])
            
            # æ ‡å‡†åŒ–æ ¼å¼
            standardized = []
            for item in items:
                standardized.append({
                    'title': item.get('title', ''),
                    'content': item.get('desc', item.get('content', '')),
                    'url': item.get('url', ''),
                    'source_name': item.get('source_name', 'DailyHot'),
                    'category': self._auto_categorize(item.get('title', '')),
                    'tags': self._extract_tags(item.get('title', '')),
                    'keywords': self._extract_keywords(item.get('title', ''))
                })
            
            return {'count': len(standardized), 'items': standardized}
        except Exception as e:
            print(f"   âŒ DailyHotApi é‡‡é›†å¤±è´¥ï¼š{e}")
            self.stats['errors'] += 1
            return {'count': 0, 'items': []}
    
    def _collect_rsshub(self) -> Dict[str, Any]:
        """é‡‡é›† RSSHub"""
        try:
            result = collect_rsshub()
            items = result.get('items', [])
            
            # æ ‡å‡†åŒ–æ ¼å¼
            standardized = []
            for item in items:
                standardized.append({
                    'title': item.get('title', ''),
                    'content': item.get('description', item.get('content', '')),
                    'url': item.get('link', item.get('url', '')),
                    'source_name': item.get('source', 'RSSHub'),
                    'category': self._auto_categorize(item.get('title', '')),
                    'tags': self._extract_tags(item.get('title', '')),
                    'keywords': self._extract_keywords(item.get('title', ''))
                })
            
            return {'count': len(standardized), 'items': standardized}
        except Exception as e:
            print(f"   âŒ RSSHub é‡‡é›†å¤±è´¥ï¼š{e}")
            self.stats['errors'] += 1
            return {'count': 0, 'items': []}
    
    def _collect_videos(self) -> Dict[str, Any]:
        """é‡‡é›†è§†é¢‘"""
        try:
            result = collect_videos()
            items = result.get('items', [])
            
            # æ ‡å‡†åŒ–æ ¼å¼
            standardized = []
            for item in items:
                standardized.append({
                    'title': item.get('title', ''),
                    'content': item.get('desc', ''),
                    'url': item.get('url', ''),
                    'source_name': item.get('platform', 'Video'),
                    'category': 'è§†é¢‘',
                    'tags': self._extract_tags(item.get('title', '')),
                    'keywords': self._extract_keywords(item.get('title', '')),
                    'extra': {
                        'play_count': item.get('play_count'),
                        'author': item.get('author')
                    }
                })
            
            return {'count': len(standardized), 'items': standardized}
        except Exception as e:
            print(f"   âŒ è§†é¢‘é‡‡é›†å¤±è´¥ï¼š{e}")
            self.stats['errors'] += 1
            return {'count': 0, 'items': []}
    
    def _save_to_database(self, items: List[Dict]) -> Dict[str, int]:
        """ä¿å­˜åˆ°æ•°æ®åº“"""
        stored = 0
        skipped = 0
        
        for item in items:
            topic_id = self.db.add_hot_topic(**item)
            
            if topic_id > 0:
                stored += 1
            else:
                skipped += 1
        
        self.stats['total_stored'] = stored
        self.stats['duplicates'] = skipped
        
        return {'stored': stored, 'skipped': skipped}
    
    def _auto_categorize(self, title: str) -> str:
        """è‡ªåŠ¨åˆ†ç±»"""
        category_keywords = {
            'ç§‘æŠ€': ['AI', 'äººå·¥æ™ºèƒ½', 'ç§‘æŠ€', 'äº’è”ç½‘', 'æ•°ç ', 'æ‰‹æœº', 'èŠ¯ç‰‡'],
            'è´¢ç»': ['è´¢ç»', 'è‚¡ç¥¨', 'åŸºé‡‘', 'æŠ•èµ„', 'ç†è´¢', 'ç»æµ', 'é‡‘è'],
            'æ•™è‚²': ['æ•™è‚²', 'å­¦æ ¡', 'è€ƒè¯•', 'åŸ¹è®­', 'å­¦ä¹ ', 'æ•™å¸ˆ', 'å­¦ç”Ÿ'],
            'å¨±ä¹': ['å¨±ä¹', 'æ˜æ˜Ÿ', 'ç”µå½±', 'ç”µè§†å‰§', 'ç»¼è‰º', 'éŸ³ä¹'],
            'ä½“è‚²': ['ä½“è‚²', 'æ¯”èµ›', 'è¿åŠ¨å‘˜', 'çƒé˜Ÿ', 'å¥¥è¿', 'è¶³çƒ', 'ç¯®çƒ'],
            'ç¤¾ä¼š': ['ç¤¾ä¼š', 'æ°‘ç”Ÿ', 'æ”¿ç­–', 'æ”¿åºœ', 'æ³•é™¢', 'å…¬å®‰']
        }
        
        for category, keywords in category_keywords.items():
            if any(kw in title for kw in keywords):
                return category
        
        return 'ç»¼åˆ'
    
    def _extract_tags(self, title: str) -> List[str]:
        """æå–æ ‡ç­¾"""
        tags = []
        
        # çƒ­ç‚¹ç±»å‹æ ‡ç­¾
        if any(kw in title for kw in ['çªå‘', 'åˆšåˆš', 'æœ€æ–°']):
            tags.append('çªå‘')
        if any(kw in title for kw in ['é‡ç£…', 'é‡è¦', 'é‡ç£…å‘å¸ƒ']):
            tags.append('é‡ç£…')
        if any(kw in title for kw in ['æ›å…‰', 'æ­ç§˜', 'å†…å¹•']):
            tags.append('æ›å…‰')
        
        # é¢†åŸŸæ ‡ç­¾
        if 'AI' in title or 'äººå·¥æ™ºèƒ½' in title:
            tags.append('AI')
        if 'æ•™è‚²' in title:
            tags.append('æ•™è‚²')
        if 'è´¢ç»' in title or 'è‚¡ç¥¨' in title:
            tags.append('è´¢ç»')
        
        return list(set(tags))
    
    def _extract_keywords(self, title: str) -> List[str]:
        """æå–å…³é”®è¯"""
        import re
        
        # ç®€å•åˆ†è¯ (2-4 å­—ä¸­æ–‡è¯)
        keywords = re.findall(r'[\u4e00-\u9fa5]{2,4}', title)
        
        # è¿‡æ»¤åœç”¨è¯
        stopwords = ['çš„', 'äº†', 'æ˜¯', 'åœ¨', 'å’Œ', 'ä¸', 'åŠ', 'ç­‰', 'å°±', 'éƒ½', 'ä¹Ÿ', 'è¿˜']
        keywords = [kw for kw in keywords if kw not in stopwords]
        
        # ä¿ç•™å‰ 10 ä¸ª
        return keywords[:10]
    
    def get_hot_topics(self, limit: int = 20, **kwargs) -> List[Dict]:
        """è·å–çƒ­ç‚¹åˆ—è¡¨ (ä»£ç†åˆ°æ•°æ®åº“)"""
        return self.db.get_hot_topics(limit=limit, **kwargs)
    
    def get_statistics(self, days: int = 7) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡æ•°æ® (ä»£ç†åˆ°æ•°æ®åº“)"""
        return self.db.get_statistics(days=days)
    
    def cleanup(self, days_to_keep: int = 30):
        """æ¸…ç†æ—§æ•°æ®"""
        return self.db.cleanup_old_data(days_to_keep)
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        self.db.close()


def test_collector_v2():
    """æµ‹è¯•é‡‡é›†å™¨ V2"""
    print("\n" + "="*70)
    print("ğŸ“¡ çƒ­ç‚¹é‡‡é›†å™¨ V2 æµ‹è¯•")
    print("="*70 + "\n")
    
    collector = HotNewsCollectorV2()
    
    # 1. é‡‡é›†æ‰€æœ‰æ•°æ®
    report = collector.collect_all(save_to_db=True)
    
    # 2. æŸ¥è¯¢çƒ­ç‚¹
    print("="*70)
    print("ğŸ“‹ æœ€æ–°çƒ­ç‚¹ TOP10")
    print("="*70 + "\n")
    
    topics = collector.get_hot_topics(limit=10)
    for i, t in enumerate(topics, 1):
        print(f"{i}. [{t['heat_level']}] {t['title'][:50]}...")
        print(f"   æ¥æºï¼š{t['source_name']} | åˆ†ç±»ï¼š{t.get('category', 'N/A')} | çƒ­åº¦ï¼š{t['heat_score']:.1f}\n")
    
    # 3. ç»Ÿè®¡
    print("="*70)
    print("ğŸ“Š ç»Ÿè®¡æ•°æ®")
    print("="*70 + "\n")
    
    stats = collector.get_statistics(days=7)
    print(f"æ€»çƒ­ç‚¹æ•°ï¼š{stats['overall']['total_count']}")
    print(f"å¹³å‡çƒ­åº¦ï¼š{stats['overall']['avg_heat']:.1f}")
    print(f"å”¯ä¸€çƒ­ç‚¹ï¼š{stats['overall']['unique_count']}")
    
    print(f"\næŒ‰åˆ†ç±»:")
    for cat in stats['by_category'][:5]:
        print(f"  - {cat['category']}: {cat['count']}æ¡ï¼Œå¹³å‡çƒ­åº¦{cat['avg_heat']:.1f}")
    
    print(f"\nçƒ­è¯ TOP10:")
    for kw in stats['hot_keywords'][:10]:
        print(f"  - {kw['keyword']}: {kw['count']}æ¬¡")
    
    collector.close()
    
    print("\n" + "="*70)
    print("ğŸ‰ é‡‡é›†å™¨ V2 æµ‹è¯•å®Œæˆ")
    print("="*70 + "\n")


if __name__ == "__main__":
    test_collector_v2()
