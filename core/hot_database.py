#!/usr/bin/env python3
"""
ã€çƒ­ç‚¹æ•°æ®åº“ã€‘Hot News Database
åŸºäº SQLite çš„çƒ­ç‚¹æ•°æ®å­˜å‚¨ä¸ç®¡ç†

æ•°æ®åº“ç»“æ„:
- hot_topics: çƒ­ç‚¹ä¸»è¡¨
- hot_sources: æ¥æºè¡¨
- hot_keywords: å…³é”®è¯è¡¨
- hot_statistics: ç»Ÿè®¡è¡¨

åŠŸèƒ½:
1. çƒ­ç‚¹å­˜å‚¨ - ç»“æ„åŒ–å­˜å‚¨çƒ­ç‚¹æ•°æ®
2. æ™ºèƒ½å»é‡ - åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦
3. çƒ­åº¦è®¡ç®— - å¤šç»´æƒé‡è¯„åˆ†
4. è¿‡æœŸæ¸…ç† - è‡ªåŠ¨æ¸…ç†æ—§æ•°æ®
5. ç»Ÿè®¡åˆ†æ - å¤šç»´åº¦æ•°æ®ç»Ÿè®¡
"""

import os
import sys
import json
import sqlite3
import hashlib
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from collections import Counter
import re

class HotNewsDatabase:
    """çƒ­ç‚¹æ•°æ®åº“"""
    
    def __init__(self, db_path: str = None):
        """
        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„ (é»˜è®¤ï¼šdata/hot_news.db)
        """
        if db_path is None:
            data_dir = os.path.join(
                os.path.dirname(os.path.dirname(__file__)),
                'data'
            )
            os.makedirs(data_dir, exist_ok=True)
            db_path = os.path.join(data_dir, 'hot_news.db')
        
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path, check_same_thread=False)
        self.conn.row_factory = sqlite3.Row
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_database()
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        cursor = self.conn.cursor()
        
        # 1. çƒ­ç‚¹ä¸»è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS hot_topics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                content TEXT,
                url TEXT,
                source_id INTEGER,
                crawl_time DATETIME NOT NULL,
                publish_time DATETIME,
                heat_score REAL DEFAULT 0,
                heat_level TEXT DEFAULT 'normal',
                category TEXT,
                tags TEXT,
                keyword_hash TEXT,
                is_unique INTEGER DEFAULT 1,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (source_id) REFERENCES hot_sources(id)
            )
        ''')
        
        # 2. æ¥æºè¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS hot_sources (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL UNIQUE,
                platform TEXT,
                category TEXT,
                base_url TEXT,
                priority INTEGER DEFAULT 5,
                credibility REAL DEFAULT 0.5,
                is_active INTEGER DEFAULT 1,
                last_crawl DATETIME,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # 3. å…³é”®è¯è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS hot_keywords (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                topic_id INTEGER,
                keyword TEXT NOT NULL,
                weight REAL DEFAULT 1.0,
                category TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (topic_id) REFERENCES hot_topics(id)
            )
        ''')
        
        # 4. ç»Ÿè®¡è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS hot_statistics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                stat_date DATE NOT NULL,
                category TEXT,
                source_id INTEGER,
                total_count INTEGER DEFAULT 0,
                avg_heat_score REAL DEFAULT 0,
                max_heat_score REAL DEFAULT 0,
                unique_count INTEGER DEFAULT 0,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(stat_date, category, source_id)
            )
        ''')
        
        # åˆ›å»ºç´¢å¼•
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_hot_topics_crawl_time ON hot_topics(crawl_time)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_hot_topics_heat ON hot_topics(heat_score)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_hot_topics_hash ON hot_topics(keyword_hash)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_hot_keywords_keyword ON hot_keywords(keyword)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_hot_statistics_date ON hot_statistics(stat_date)')
        
        self.conn.commit()
        print(f"[DB] âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸï¼š{self.db_path}")
    
    # ========== æ¥æºç®¡ç† ==========
    
    def add_source(self, name: str, platform: str = None, 
                   category: str = None, base_url: str = None,
                   priority: int = 5, credibility: float = 0.5) -> int:
        """æ·»åŠ æ•°æ®æº"""
        cursor = self.conn.cursor()
        
        try:
            cursor.execute('''
                INSERT OR REPLACE INTO hot_sources 
                (name, platform, category, base_url, priority, credibility)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (name, platform, category, base_url, priority, credibility))
            
            self.conn.commit()
            source_id = cursor.lastrowid
            print(f"[DB] âœ… æ·»åŠ æ•°æ®æºï¼š{name} (ID: {source_id})")
            return source_id
        except Exception as e:
            print(f"[DB] âŒ æ·»åŠ æ•°æ®æºå¤±è´¥ï¼š{e}")
            return -1
    
    def get_sources(self, category: str = None, active_only: bool = True) -> List[Dict]:
        """è·å–æ•°æ®æºåˆ—è¡¨"""
        cursor = self.conn.cursor()
        
        query = 'SELECT * FROM hot_sources'
        params = []
        
        if active_only:
            query += ' WHERE is_active = 1'
        
        if category:
            query += ' AND category = ?' if active_only else ' WHERE category = ?'
            params.append(category)
        
        query += ' ORDER BY priority DESC, credibility DESC'
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        
        return [dict(row) for row in rows]
    
    # ========== çƒ­ç‚¹å­˜å‚¨ ==========
    
    def add_hot_topic(self, title: str, content: str = None,
                     url: str = None, source_name: str = None,
                     crawl_time: datetime = None, publish_time: datetime = None,
                     heat_score: float = None, category: str = None,
                     tags: List[str] = None, keywords: List[str] = None) -> int:
        """
        æ·»åŠ çƒ­ç‚¹
        
        Args:
            title: çƒ­ç‚¹æ ‡é¢˜
            content: å†…å®¹æ‘˜è¦
            url: åŸæ–‡é“¾æ¥
            source_name: æ¥æºåç§°
            crawl_time: é‡‡é›†æ—¶é—´
            publish_time: å‘å¸ƒæ—¶é—´
            heat_score: çƒ­åº¦å€¼ (0-100)
            category: åˆ†ç±»
            tags: æ ‡ç­¾åˆ—è¡¨
            keywords: å…³é”®è¯åˆ—è¡¨
        
        Returns:
            çƒ­ç‚¹ ID
        """
        cursor = self.conn.cursor()
        
        # 1. è·å–æˆ–åˆ›å»ºæ¥æº
        source_id = self._get_or_create_source(source_name)
        
        # 2. è®¡ç®—å…³é”®è¯å“ˆå¸Œ (ç”¨äºå»é‡)
        keyword_hash = self._calculate_keyword_hash(title, keywords)
        
        # 3. æ£€æŸ¥æ˜¯å¦é‡å¤
        existing = self._check_duplicate(keyword_hash, title)
        if existing:
            print(f"[DB] âš ï¸ æ£€æµ‹åˆ°é‡å¤çƒ­ç‚¹ï¼š{title[:30]}...")
            return -1
        
        # 4. è®¾ç½®é»˜è®¤å€¼
        if crawl_time is None:
            crawl_time = datetime.now()
        if heat_score is None:
            heat_score = self._calculate_heat_score(title, content, source_name)
        
        # 5. æ’å…¥æ•°æ®åº“
        cursor.execute('''
            INSERT INTO hot_topics 
            (title, content, url, source_id, crawl_time, publish_time, 
             heat_score, heat_level, category, tags, keyword_hash)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            title, content, url, source_id,
            crawl_time.isoformat() if crawl_time else None,
            publish_time.isoformat() if publish_time else None,
            heat_score,
            self._get_heat_level(heat_score),
            category,
            json.dumps(tags, ensure_ascii=False) if tags else None,
            keyword_hash
        ))
        
        topic_id = cursor.lastrowid
        
        # 6. æ·»åŠ å…³é”®è¯
        if keywords:
            self._add_keywords(topic_id, keywords)
        
        self.conn.commit()
        print(f"[DB] âœ… æ·»åŠ çƒ­ç‚¹ï¼š{title[:30]}... (ID: {topic_id}, çƒ­åº¦ï¼š{heat_score})")
        return topic_id
    
    def _get_or_create_source(self, source_name: str) -> int:
        """è·å–æˆ–åˆ›å»ºæ¥æº"""
        if not source_name:
            return 1  # é»˜è®¤æ¥æº
        
        cursor = self.conn.cursor()
        cursor.execute('SELECT id FROM hot_sources WHERE name = ?', (source_name,))
        row = cursor.fetchone()
        
        if row:
            return row['id']
        
        # åˆ›å»ºæ–°æ¥æº
        return self.add_source(source_name)
    
    def _calculate_keyword_hash(self, title: str, keywords: List[str] = None) -> str:
        """è®¡ç®—å…³é”®è¯å“ˆå¸Œ"""
        # æå–å…³é”®è¯
        if keywords:
            kw_text = ' '.join(keywords)
        else:
            # ç®€å•åˆ†è¯
            kw_text = re.sub(r'[^\w\s\u4e00-\u9fa5]', '', title)
        
        # è®¡ç®—å“ˆå¸Œ
        hash_md5 = hashlib.md5(kw_text.encode('utf-8')).hexdigest()
        return hash_md5
    
    def _check_duplicate(self, keyword_hash: str, title: str, 
                        time_window_hours: int = 24) -> bool:
        """æ£€æŸ¥æ˜¯å¦é‡å¤"""
        cursor = self.conn.cursor()
        
        # æ—¶é—´çª—å£
        time_threshold = datetime.now() - timedelta(hours=time_window_hours)
        
        # æ£€æŸ¥å“ˆå¸Œç›¸åŒ
        cursor.execute('''
            SELECT id FROM hot_topics 
            WHERE keyword_hash = ? AND crawl_time > ?
        ''', (keyword_hash, time_threshold.isoformat()))
        
        if cursor.fetchone():
            return True
        
        # æ£€æŸ¥æ ‡é¢˜ç›¸ä¼¼åº¦ (ç®€å•åŒ¹é…)
        cursor.execute('''
            SELECT id FROM hot_topics 
            WHERE title LIKE ? AND crawl_time > ?
        ''', (f'%{title[:20]}%', time_threshold.isoformat()))
        
        return cursor.fetchone() is not None
    
    def _calculate_heat_score(self, title: str, content: str = None,
                             source_name: str = None) -> float:
        """è®¡ç®—çƒ­åº¦å€¼"""
        score = 50.0  # åŸºç¡€åˆ†
        
        # 1. æ ‡é¢˜é•¿åº¦ (20-40 å­—æœ€ä½³)
        title_len = len(title)
        if 20 <= title_len <= 40:
            score += 10
        elif 10 <= title_len < 20 or 40 < title_len <= 60:
            score += 5
        
        # 2. æ¥æºå¯ä¿¡åº¦
        source_credibility = self._get_source_credibility(source_name)
        score += source_credibility * 20
        
        # 3. å†…å®¹é•¿åº¦
        if content:
            content_len = len(content)
            if 100 <= content_len <= 500:
                score += 10
            elif content_len > 500:
                score += 5
        
        # 4. çƒ­ç‚¹å…³é”®è¯
        hot_keywords = ['çªå‘', 'é‡ç£…', 'æœ€æ–°', 'åˆšåˆš', 'éœ‡æƒŠ', 'æ›å…‰']
        if any(kw in title for kw in hot_keywords):
            score += 5
        
        return min(100, max(0, score))
    
    def _get_source_credibility(self, source_name: str) -> float:
        """è·å–æ¥æºå¯ä¿¡åº¦"""
        if not source_name:
            return 0.5
        
        cursor = self.conn.cursor()
        cursor.execute('SELECT credibility FROM hot_sources WHERE name = ?', (source_name,))
        row = cursor.fetchone()
        
        return row['credibility'] if row else 0.5
    
    def _get_heat_level(self, heat_score: float) -> str:
        """è·å–çƒ­åº¦ç­‰çº§"""
        if heat_score >= 90:
            return 'explosive'  # çˆ†æ¬¾
        elif heat_score >= 75:
            return 'hot'  # çƒ­é—¨
        elif heat_score >= 60:
            return 'warm'  # æ¸©çƒ­ç‚¹
        else:
            return 'normal'  # æ™®é€š
    
    def _add_keywords(self, topic_id: int, keywords: List[str]):
        """æ·»åŠ å…³é”®è¯"""
        cursor = self.conn.cursor()
        
        for keyword in keywords:
            cursor.execute('''
                INSERT INTO hot_keywords (topic_id, keyword, weight)
                VALUES (?, ?, ?)
            ''', (topic_id, keyword, 1.0))
    
    # ========== çƒ­ç‚¹æŸ¥è¯¢ ==========
    
    def get_hot_topics(self, limit: int = 20, 
                      category: str = None,
                      heat_level: str = None,
                      source_name: str = None,
                      time_range_hours: int = None) -> List[Dict]:
        """
        è·å–çƒ­ç‚¹åˆ—è¡¨
        
        Args:
            limit: è¿”å›æ•°é‡
            category: åˆ†ç±»è¿‡æ»¤
            heat_level: çƒ­åº¦ç­‰çº§è¿‡æ»¤
            source_name: æ¥æºè¿‡æ»¤
            time_range_hours: æ—¶é—´èŒƒå›´ (å°æ—¶)
        """
        cursor = self.conn.cursor()
        
        query = '''
            SELECT t.*, s.name as source_name, s.platform, s.category as source_category
            FROM hot_topics t
            LEFT JOIN hot_sources s ON t.source_id = s.id
            WHERE 1=1
        '''
        params = []
        
        if category:
            query += ' AND (t.category = ? OR s.category = ?)'
            params.extend([category, category])
        
        if heat_level:
            query += ' AND t.heat_level = ?'
            params.append(heat_level)
        
        if source_name:
            query += ' AND s.name = ?'
            params.append(source_name)
        
        if time_range_hours:
            time_threshold = datetime.now() - timedelta(hours=time_range_hours)
            query += ' AND t.crawl_time > ?'
            params.append(time_threshold.isoformat())
        
        query += ' ORDER BY t.heat_score DESC, t.crawl_time DESC'
        query += ' LIMIT ?'
        params.append(limit)
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        
        results = []
        for row in rows:
            item = dict(row)
            # è§£æ tags
            if item.get('tags'):
                try:
                    item['tags'] = json.loads(item['tags'])
                except:
                    item['tags'] = []
            results.append(item)
        
        return results
    
    def get_keywords_by_topic(self, topic_id: int) -> List[Dict]:
        """è·å–çƒ­ç‚¹çš„å…³é”®è¯"""
        cursor = self.conn.cursor()
        cursor.execute('''
            SELECT * FROM hot_keywords 
            WHERE topic_id = ? 
            ORDER BY weight DESC
        ''', (topic_id,))
        
        return [dict(row) for row in cursor.fetchall()]
    
    # ========== ç»Ÿè®¡åˆ†æ ==========
    
    def get_statistics(self, days: int = 7) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡æ•°æ®"""
        cursor = self.conn.cursor()
        
        # æ—¶é—´èŒƒå›´
        time_threshold = datetime.now() - timedelta(days=days)
        
        # æ€»ä½“ç»Ÿè®¡
        cursor.execute('''
            SELECT 
                COUNT(*) as total_count,
                AVG(heat_score) as avg_heat,
                MAX(heat_score) as max_heat,
                COUNT(DISTINCT keyword_hash) as unique_count
            FROM hot_topics
            WHERE crawl_time > ?
        ''', (time_threshold.isoformat(),))
        
        overall = dict(cursor.fetchone())
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        cursor.execute('''
            SELECT category, COUNT(*) as count, AVG(heat_score) as avg_heat
            FROM hot_topics
            WHERE crawl_time > ? AND category IS NOT NULL
            GROUP BY category
            ORDER BY count DESC
        ''', (time_threshold.isoformat(),))
        
        by_category = [dict(row) for row in cursor.fetchall()]
        
        # æŒ‰æ¥æºç»Ÿè®¡
        cursor.execute('''
            SELECT s.name, s.platform, COUNT(t.id) as count, AVG(t.heat_score) as avg_heat
            FROM hot_topics t
            LEFT JOIN hot_sources s ON t.source_id = s.id
            WHERE t.crawl_time > ?
            GROUP BY s.name, s.platform
            ORDER BY count DESC
            LIMIT 20
        ''', (time_threshold.isoformat(),))
        
        by_source = [dict(row) for row in cursor.fetchall()]
        
        # çƒ­è¯ç»Ÿè®¡
        cursor.execute('''
            SELECT k.keyword, COUNT(*) as count, AVG(k.weight) as avg_weight
            FROM hot_keywords k
            INNER JOIN hot_topics t ON k.topic_id = t.id
            WHERE t.crawl_time > ?
            GROUP BY k.keyword
            ORDER BY count DESC
            LIMIT 50
        ''', (time_threshold.isoformat(),))
        
        hot_keywords = [dict(row) for row in cursor.fetchall()]
        
        return {
            'overall': overall,
            'by_category': by_category,
            'by_source': by_source,
            'hot_keywords': hot_keywords,
            'time_range': f'{days} days'
        }
    
    # ========== æ•°æ®æ¸…ç† ==========
    
    def cleanup_old_data(self, days_to_keep: int = 30) -> int:
        """æ¸…ç†æ—§æ•°æ®"""
        cursor = self.conn.cursor()
        
        time_threshold = datetime.now() - timedelta(days=days_to_keep)
        
        # åˆ é™¤æ—§çƒ­ç‚¹
        cursor.execute('''
            DELETE FROM hot_topics WHERE crawl_time < ?
        ''', (time_threshold.isoformat(),))
        
        deleted = cursor.rowcount
        
        # åˆ é™¤å­¤ç«‹å…³é”®è¯
        cursor.execute('''
            DELETE FROM hot_keywords 
            WHERE topic_id NOT IN (SELECT id FROM hot_topics)
        ''')
        
        self.conn.commit()
        print(f"[DB] âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤ {deleted} æ¡æ—§çƒ­ç‚¹")
        
        return deleted
    
    # ========== æ‰¹é‡æ“ä½œ ==========
    
    def batch_add_topics(self, topics: List[Dict]) -> Dict[str, int]:
        """
        æ‰¹é‡æ·»åŠ çƒ­ç‚¹
        
        Args:
            topics: çƒ­ç‚¹åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«ï¼š
                - title (å¿…éœ€)
                - content (å¯é€‰)
                - url (å¯é€‰)
                - source_name (å¯é€‰)
                - category (å¯é€‰)
                - tags (å¯é€‰)
                - keywords (å¯é€‰)
        
        Returns:
            {"added": æˆåŠŸæ•°ï¼Œ"skipped": è·³è¿‡æ•° (é‡å¤)}
        """
        stats = {"added": 0, "skipped": 0}
        
        for topic in topics:
            topic_id = self.add_hot_topic(**topic)
            
            if topic_id > 0:
                stats["added"] += 1
            else:
                stats["skipped"] += 1
        
        return stats
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()


# ========== ä¾¿æ·å‡½æ•° ==========

def get_hot_db() -> HotNewsDatabase:
    """è·å–æ•°æ®åº“å®ä¾‹"""
    return HotNewsDatabase()


def test_hot_database():
    """æµ‹è¯•æ•°æ®åº“"""
    print("\n" + "="*70)
    print("ğŸ—„ï¸  çƒ­ç‚¹æ•°æ®åº“æµ‹è¯•")
    print("="*70 + "\n")
    
    db = get_hot_db()
    
    # 1. æ·»åŠ æ•°æ®æº
    print("Step 1: æ·»åŠ æ•°æ®æº")
    db.add_source("å¾®åšçƒ­æœ", platform="å¾®åš", category="ç»¼åˆ", priority=10, credibility=0.8)
    db.add_source("çŸ¥ä¹çƒ­æ¦œ", platform="çŸ¥ä¹", category="ç»¼åˆ", priority=9, credibility=0.85)
    db.add_source("æ¾æ¹ƒæ–°é—»", platform="æ¾æ¹ƒæ–°é—»", category="æ–°é—»", priority=8, credibility=0.9)
    
    # 2. æ·»åŠ çƒ­ç‚¹
    print("\nStep 2: æ·»åŠ çƒ­ç‚¹")
    db.add_hot_topic(
        title="æ•™è‚²éƒ¨å‘å¸ƒ AI+ æ•™è‚²æŒ‡å¯¼æ„è§ï¼Œ60% é«˜æ ¡å·²å¼€è®¾ç›¸å…³è¯¾ç¨‹",
        content="æ•™è‚²éƒ¨è¿‘æ—¥å‘å¸ƒã€Šäººå·¥æ™ºèƒ½ + æ•™è‚²ã€‹æŒ‡å¯¼æ„è§ï¼Œæå‡ºåˆ° 2025 å¹´...",
        url="https://example.com/news/123",
        source_name="æ¾æ¹ƒæ–°é—»",
        category="æ•™è‚²",
        tags=["AI", "æ•™è‚²", "æ”¿ç­–"],
        keywords=["æ•™è‚²éƒ¨", "AI æ•™è‚²", "é«˜æ ¡è¯¾ç¨‹"]
    )
    
    db.add_hot_topic(
        title="AI ç¨‹åºå‘˜å¤±ä¸šæ½®æ¥äº†ï¼Ÿä¸“å®¶ï¼šä¸ä¼šç”¨ AI çš„æ‰ä¼šè¢«æ·˜æ±°",
        content="è¿‘æ—¥ï¼ŒæŸå¤§å‚å®£å¸ƒè£å‘˜ 30%ï¼Œå…¶ä¸­ç¨‹åºå‘˜å æ¯”æœ€é«˜...",
        url="https://example.com/news/124",
        source_name="çŸ¥ä¹çƒ­æ¦œ",
        category="ç§‘æŠ€",
        tags=["AI", "å°±ä¸š", "ç¨‹åºå‘˜"],
        keywords=["AI", "ç¨‹åºå‘˜", "å¤±ä¸š", "è£å‘˜"]
    )
    
    # 3. æŸ¥è¯¢çƒ­ç‚¹
    print("\nStep 3: æŸ¥è¯¢çƒ­ç‚¹")
    topics = db.get_hot_topics(limit=5)
    for i, t in enumerate(topics, 1):
        print(f"  {i}. [{t['heat_level']}] {t['title'][:40]}...")
        print(f"     æ¥æºï¼š{t['source_name']} | çƒ­åº¦ï¼š{t['heat_score']:.1f}")
    
    # 4. ç»Ÿè®¡
    print("\nStep 4: ç»Ÿè®¡æ•°æ®")
    stats = db.get_statistics(days=7)
    print(f"  æ€»çƒ­ç‚¹æ•°ï¼š{stats['overall']['total_count']}")
    print(f"  å¹³å‡çƒ­åº¦ï¼š{stats['overall']['avg_heat']:.1f}")
    print(f"  å”¯ä¸€çƒ­ç‚¹ï¼š{stats['overall']['unique_count']}")
    
    print(f"\n  æŒ‰åˆ†ç±»:")
    for cat in stats['by_category'][:3]:
        print(f"    - {cat['category']}: {cat['count']}æ¡")
    
    print(f"\n  çƒ­è¯ TOP5:")
    for kw in stats['hot_keywords'][:5]:
        print(f"    - {kw['keyword']}: {kw['count']}æ¬¡")
    
    # 5. æµ‹è¯•å»é‡
    print("\nStep 5: æµ‹è¯•å»é‡")
    topic_id = db.add_hot_topic(
        title="æ•™è‚²éƒ¨å‘å¸ƒ AI+ æ•™è‚²æŒ‡å¯¼æ„è§ï¼Œ60% é«˜æ ¡å·²å¼€è®¾ç›¸å…³è¯¾ç¨‹",
        source_name="æ¾æ¹ƒæ–°é—»"
    )
    print(f"  é‡å¤çƒ­ç‚¹ ID: {topic_id} (åº”ä¸º -1)")
    
    print("\n" + "="*70)
    print("ğŸ‰ æ•°æ®åº“æµ‹è¯•å®Œæˆ")
    print("="*70 + "\n")
    
    db.close()


if __name__ == "__main__":
    test_hot_database()
