#!/usr/bin/env python3
"""
é€‰é¢˜æ·±åº¦åˆ†æå™¨
ä¸ºæ¯ä¸ªé€‰é¢˜æä¾›å…·ä½“çš„å†™ä½œåˆ†æï¼Œå¸®åŠ©ç”¨æˆ·åˆ¤æ–­æ˜¯å¦å€¼å¾—å†™

ä½œè€…: AI Article Publisher
åˆ›å»ºæ—¶é—´: 2026-02-22
"""

import json
import os
import sys
from datetime import datetime
from typing import List, Dict, Any

# é…ç½®
CONFIG = {
    "user_domains": ["æ•™è‚²", "å¿ƒç†å­¦", "AI", "ç§‘æŠ€", "ä¸ªäººæˆé•¿"],
    "min_hotness": 100,  # æœ€å°çƒ­åº¦é˜ˆå€¼
}


def analyze_topic_deeply(topic: Dict, user_domains: List[str] = None) -> Dict:
    """
    æ·±åº¦åˆ†æå•ä¸ªé€‰é¢˜
    
    è¿”å›:
    - æ˜¯å¦å€¼å¾—å†™
    - ä¸ºä»€ä¹ˆå€¼å¾—/ä¸å€¼å¾—
    - å†™ä½œéš¾åº¦è¯„ä¼°
    - å…·ä½“å»ºè®®
    """
    user_domains = user_domains or CONFIG["user_domains"]
    
    title = topic.get("title", "")
    source = topic.get("source_name", topic.get("source", ""))
    category = topic.get("category", "")
    
    analysis = {
        "title": title,
        "source": source,
        "category": category,
        "worth_writing": False,
        "reasons": [],
        "concerns": [],
        "suggestions": [],
        "score": 0,
    }
    
    # 1. æ£€æŸ¥æ˜¯å¦ä¸ç”¨æˆ·é¢†åŸŸç›¸å…³
    domain_match = False
    matched_domains = []
    
    domain_keywords = {
        "æ•™è‚²": ["æ•™è‚²", "å­¦æ ¡", "å­¦ç”Ÿ", "è€å¸ˆ", "æ•™å­¦", "å­¦ä¹ ", "è¯¾ç¨‹", "å¤§å­¦", "é«˜è€ƒ", "è€ƒç ”"],
        "å¿ƒç†å­¦": ["å¿ƒç†", "æƒ…ç»ª", "å‹åŠ›", "ç„¦è™‘", "è®¤çŸ¥", "å¤§è„‘", "ç¥ç»", "è®°å¿†", "æ€ç»´", "è¡Œä¸º"],
        "AI": ["AI", "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "GPT", "Claude", "LLM", "æ·±åº¦å­¦ä¹ ", "ç®—æ³•", "æ¨¡å‹"],
        "ç§‘æŠ€": ["ç§‘æŠ€", "æŠ€æœ¯", "äº’è”ç½‘", "è½¯ä»¶", "ç¡¬ä»¶", "ç¼–ç¨‹", "ä»£ç ", "å¼€å‘", "äº§å“"],
        "ä¸ªäººæˆé•¿": ["æˆé•¿", "å­¦ä¹ ", "æ•ˆç‡", "ä¹ æƒ¯", "æ—¶é—´", "ç›®æ ‡", "æˆåŠŸ", "å¤±è´¥", "æ”¹å˜"],
    }
    
    for domain, keywords in domain_keywords.items():
        if domain in user_domains:
            for kw in keywords:
                if kw.lower() in title.lower():
                    matched_domains.append(domain)
                    break
    
    if matched_domains:
        domain_match = True
        analysis["matched_domains"] = matched_domains
        analysis["reasons"].append(f"âœ… åŒ¹é…ä½ çš„é¢†åŸŸ: {', '.join(matched_domains)}")
        analysis["score"] += 20
    else:
        analysis["concerns"].append("âŒ ä¸ä½ çš„ä¸“ä¸šé¢†åŸŸä¸å¤ªåŒ¹é…")
    
    # 2. æ£€æŸ¥é€‰é¢˜ç±»å‹
    topic_type = detect_topic_type(title)
    analysis["topic_type"] = topic_type
    
    if topic_type == "çƒ­ç‚¹äº‹ä»¶":
        analysis["reasons"].append("âœ… çƒ­ç‚¹äº‹ä»¶ï¼Œæœ‰æ—¶æ•ˆæ€§")
        analysis["suggestions"].append("å»ºè®® 24-48 å°æ—¶å†…å‘å¸ƒ")
        analysis["score"] += 15
    elif topic_type == "çŸ¥è¯†ç§‘æ™®":
        analysis["reasons"].append("âœ… çŸ¥è¯†ç§‘æ™®ç±»ï¼Œé•¿å°¾ä»·å€¼é«˜")
        analysis["suggestions"].append("å¯ä»¥æ·±åº¦æŒ–æ˜ï¼Œä¸å—æ—¶æ•ˆé™åˆ¶")
        analysis["score"] += 25
    elif topic_type == "è§‚ç‚¹äº‰è®®":
        analysis["reasons"].append("âœ… æœ‰äº‰è®®æ€§ï¼Œå®¹æ˜“å¼•å‘è®¨è®º")
        analysis["score"] += 20
    elif topic_type == "å¨±ä¹å…«å¦":
        analysis["concerns"].append("âš ï¸ å¨±ä¹å…«å¦ç±»ï¼Œç«äº‰æ¿€çƒˆ")
        analysis["suggestions"].append("éœ€è¦ç‹¬ç‰¹è§’åº¦æ‰èƒ½è„±é¢–è€Œå‡º")
    elif topic_type == "çº¯æ–°é—»":
        analysis["concerns"].append("âš ï¸ çº¯æ–°é—»ç±»ï¼Œç¼ºä¹æ·±åº¦")
        analysis["suggestions"].append("å»ºè®®æ‰¾è§’åº¦åšæ·±åº¦è§£è¯»")
    
    # 3. æ£€æŸ¥å†™ä½œéš¾åº¦
    difficulty = assess_writing_difficulty(title, category)
    analysis["difficulty"] = difficulty
    
    if difficulty == "ä½":
        analysis["reasons"].append("âœ… å†™ä½œéš¾åº¦ä½ï¼Œå®¹æ˜“ä¸Šæ‰‹")
        analysis["score"] += 10
    elif difficulty == "é«˜":
        analysis["concerns"].append("âš ï¸ å†™ä½œéš¾åº¦é«˜ï¼Œéœ€è¦ä¸“ä¸šçŸ¥è¯†")
        analysis["suggestions"].append("å»ºè®®å…ˆåšèµ„æ–™æ”¶é›†")
    
    # 4. æ£€æŸ¥ç‹¬ç‰¹æ€§æœºä¼š
    uniqueness = check_uniqueness(title, category)
    analysis["uniqueness"] = uniqueness
    
    if uniqueness == "é«˜":
        analysis["reasons"].append("âœ… ç‹¬ç‰¹æ€§é«˜ï¼Œç«äº‰å°‘")
        analysis["score"] += 15
    elif uniqueness == "ä½":
        analysis["concerns"].append("âš ï¸ åŒç±»é€‰é¢˜å¤šï¼Œç«äº‰æ¿€çƒˆ")
        analysis["suggestions"].append("éœ€è¦æ‰¾å·®å¼‚åŒ–è§’åº¦")
    
    # 5. æœ€ç»ˆåˆ¤æ–­
    analysis["score"] = min(analysis["score"], 100)
    
    if analysis["score"] >= 60:
        analysis["worth_writing"] = True
        if analysis["score"] >= 80:
            analysis["recommendation"] = "å¼ºçƒˆæ¨è"
        elif analysis["score"] >= 70:
            analysis["recommendation"] = "æ¨è"
        else:
            analysis["recommendation"] = "å¯ä»¥å†™"
    else:
        analysis["recommendation"] = "ä¸å¤ªæ¨è"
    
    return analysis


def detect_topic_type(title: str) -> str:
    """æ£€æµ‹é€‰é¢˜ç±»å‹"""
    
    # çƒ­ç‚¹äº‹ä»¶
    hot_keywords = ["çƒ­æœ", "çƒ­æ¦œ", "æœ€æ–°", "çªå‘", "åˆšåˆš", "ä»Šå¤©", "æ˜¨æ—¥"]
    for kw in hot_keywords:
        if kw in title:
            return "çƒ­ç‚¹äº‹ä»¶"
    
    # çŸ¥è¯†ç§‘æ™®
    science_keywords = ["ç ”ç©¶", "å‘ç°", "ç§‘å­¦", "åŸç†", "æœºåˆ¶", "å¦‚ä½•", "ä¸ºä»€ä¹ˆ", "ä»€ä¹ˆæ˜¯"]
    for kw in science_keywords:
        if kw in title:
            return "çŸ¥è¯†ç§‘æ™®"
    
    # è§‚ç‚¹äº‰è®®
    debate_keywords = ["äº‰è®®", "è´¨ç–‘", "åå¯¹", "æ”¯æŒ", "åº”è¯¥", "ä¸è¯¥", "å¯¹é”™"]
    for kw in debate_keywords:
        if kw in title:
            return "è§‚ç‚¹äº‰è®®"
    
    # å¨±ä¹å…«å¦
    entertainment_keywords = ["æ˜æ˜Ÿ", "æ¼”å‘˜", "æ­Œæ‰‹", "ç”µå½±", "ç”µè§†å‰§", "ç»¼è‰º", "æ‹æƒ…", "åˆ†æ‰‹"]
    for kw in entertainment_keywords:
        if kw in title:
            return "å¨±ä¹å…«å¦"
    
    # çº¯æ–°é—»
    news_keywords = ["å®£å¸ƒ", "å‘å¸ƒ", "é€šæŠ¥", "æŠ¥é“", "æ¶ˆæ¯ç§°"]
    for kw in news_keywords:
        if kw in title:
            return "çº¯æ–°é—»"
    
    return "å…¶ä»–"


def assess_writing_difficulty(title: str, category: str) -> str:
    """è¯„ä¼°å†™ä½œéš¾åº¦"""
    
    # é«˜éš¾åº¦å…³é”®è¯
    hard_keywords = ["ç ”ç©¶", "å®éªŒ", "æ•°æ®", "åˆ†æ", "æŠ€æœ¯ç»†èŠ‚", "ç®—æ³•", "åŸç†"]
    hard_count = sum(1 for kw in hard_keywords if kw in title)
    
    # ä½éš¾åº¦å…³é”®è¯
    easy_keywords = ["æ¨è", "åˆ†äº«", "ä½“éªŒ", "æ„Ÿå—", "æ•…äº‹", "è§‚ç‚¹", "æ–¹æ³•"]
    easy_count = sum(1 for kw in easy_keywords if kw in title)
    
    if hard_count >= 2:
        return "é«˜"
    elif easy_count >= 2:
        return "ä½"
    else:
        return "ä¸­"


def check_uniqueness(title: str, category: str) -> str:
    """æ£€æŸ¥ç‹¬ç‰¹æ€§"""
    
    # é€šç”¨é€‰é¢˜ï¼ˆç«äº‰å¤§ï¼‰
    generic_patterns = [
        "å¦‚ä½•", "æ€ä¹ˆ", "ä»€ä¹ˆ", "ä¸ºä»€ä¹ˆ",  # å¤ªé€šç”¨
        "ç›˜ç‚¹", "æ¨è", "åˆé›†",  # å†…å®¹å†œåœºå¸¸ç”¨
    ]
    
    # ä¸“ä¸šé€‰é¢˜ï¼ˆç«äº‰å°ï¼‰
    professional_patterns = [
        "ç ”ç©¶", "å®éªŒ", "æ•°æ®", "åˆ†æ",  # éœ€è¦ä¸“ä¸šèƒŒæ™¯
        "å¯¹æ¯”", "è¯„æµ‹", "æ·±åº¦",  # éœ€è¦æŠ•å…¥æ—¶é—´
    ]
    
    generic_count = sum(1 for p in generic_patterns if p in title)
    professional_count = sum(1 for p in professional_patterns if p in title)
    
    if professional_count >= 2:
        return "é«˜"
    elif generic_count >= 2:
        return "ä½"
    else:
        return "ä¸­"


def generate_analysis_report(analyses: List[Dict]) -> str:
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    
    lines = [
        "=" * 70,
        "é€‰é¢˜æ·±åº¦åˆ†ææŠ¥å‘Š",
        f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        f"åˆ†ææ•°é‡: {len(analyses)} ä¸ªé€‰é¢˜",
        "=" * 70,
        "",
    ]
    
    # åˆ†ç±»ç»Ÿè®¡
    worth_writing = [a for a in analyses if a["worth_writing"]]
    not_recommended = [a for a in analyses if not a["worth_writing"]]
    
    lines.append(f"ğŸ“Š ç»Ÿè®¡:")
    lines.append(f"  âœ… å€¼å¾—å†™: {len(worth_writing)} ä¸ª")
    lines.append(f"  âŒ ä¸å¤ªæ¨è: {len(not_recommended)} ä¸ª")
    lines.append("")
    
    # æ¨èé€‰é¢˜
    if worth_writing:
        lines.append("=" * 70)
        lines.append("ğŸ”¥ å€¼å¾—å†™çš„é€‰é¢˜")
        lines.append("=" * 70)
        lines.append("")
        
        for i, a in enumerate(sorted(worth_writing, key=lambda x: x["score"], reverse=True), 1):
            lines.append(f"ã€{i}ã€‘{a['title']}")
            lines.append(f"    æ¥æº: {a['source']} | åˆ†ç±»: {a['category']}")
            lines.append(f"    è¯„åˆ†: {a['score']} | {a['recommendation']}")
            lines.append(f"    ç±»å‹: {a.get('topic_type', 'æœªçŸ¥')} | éš¾åº¦: {a.get('difficulty', 'æœªçŸ¥')} | ç‹¬ç‰¹æ€§: {a.get('uniqueness', 'æœªçŸ¥')}")
            lines.append("")
            
            if a.get("reasons"):
                lines.append("    âœ… ä¼˜åŠ¿:")
                for reason in a["reasons"]:
                    lines.append(f"       {reason}")
                lines.append("")
            
            if a.get("concerns"):
                lines.append("    âš ï¸ æ³¨æ„:")
                for concern in a["concerns"]:
                    lines.append(f"       {concern}")
                lines.append("")
            
            if a.get("suggestions"):
                lines.append("    ğŸ’¡ å»ºè®®:")
                for suggestion in a["suggestions"]:
                    lines.append(f"       {suggestion}")
                lines.append("")
            
            lines.append("-" * 70)
            lines.append("")
    
    # ä¸æ¨èé€‰é¢˜
    if not_recommended:
        lines.append("=" * 70)
        lines.append("âŒ ä¸å¤ªæ¨èçš„é€‰é¢˜ (ä»…ä¾›å‚è€ƒ)")
        lines.append("=" * 70)
        lines.append("")
        
        for a in not_recommended[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            lines.append(f"  â€¢ {a['title']}")
            lines.append(f"    åŸå› : {a['concerns'][0] if a.get('concerns') else 'ç»¼åˆè¯„åˆ†è¾ƒä½'}")
            lines.append("")
    
    return "\n".join(lines)


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='é€‰é¢˜æ·±åº¦åˆ†æå™¨')
    parser.add_argument('--input', '-i', help='è¾“å…¥JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--top', '-n', type=int, default=20, help='åˆ†ææ•°é‡')
    parser.add_argument('--domains', '-d', default='æ•™è‚²,å¿ƒç†å­¦,AI,ç§‘æŠ€,ä¸ªäººæˆé•¿', help='ç”¨æˆ·å…³æ³¨é¢†åŸŸ')
    args = parser.parse_args()
    
    user_domains = [d.strip() for d in args.domains.split(',')]
    
    # åŠ è½½æ•°æ®
    if args.input:
        with open(args.input, 'r', encoding='utf-8') as f:
            data = json.load(f)
        topics = list(data.values()) if isinstance(data, dict) else data
    else:
        print("è¯·æŒ‡å®šè¾“å…¥æ–‡ä»¶")
        return
    
    # åˆ†æé€‰é¢˜
    print(f"\næ­£åœ¨åˆ†æ {min(len(topics), args.top)} ä¸ªé€‰é¢˜...")
    
    analyses = []
    for i, topic in enumerate(topics[:args.top]):
        analysis = analyze_topic_deeply(topic, user_domains)
        analyses.append(analysis)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = generate_analysis_report(analyses)
    print(report)


if __name__ == '__main__':
    main()
