# 📦 AI Article Publisher V2 - 模块详案与落地图谱 (Detailed Module Plan)

> **导读**: 此文档是 `EXECUTION_PLAN_V2.md` 的向下具象化指令单。将抽象的流转概念，转化为精确到函数级、Prompt 设计级以及入参/出参边界的实弹级实施大纲。

---

## 模块一：🧩 Topic Discovery (全网嗅探与降噪选品)
*   **输入**: 全网 95+ 抓取通道产生的 3000+ 条原始生热点 (JSON)。
*   **输出**: 提炼出的顶配每日 `Top 5 Topic Object` (包含对冲点、反转核心逻辑)。

### 1-A. `cluster.py` (降噪压缩机)
*   **实现原理**: 读取当日 `hotnews`，运用本地 `scikit-learn` 中的 `TfidfVectorizer` 将同类项聚合。
*   **目的**: 将榜单中“微博：微信网崩了”、“百度：微信电脑版无法登录”强行收束为 1 个统一超级事件块：`[微信后端基础崩盘事件]`。极大节省大模型算力，杜绝盲目重复。

### 1-B. `probe.py` (红海探查雷达)
*   **实现原理**: 利用 `Brave Search MCP` 向国内引擎发送请求。
*   **探测规则**: 拿着 LLM 选好的切入点检索。如果近 12 小时内出现 5 条以上相关雷同文案，强制触发“熔断异常”。转入强行的“唱反调视角”。

---

## 模块二：📡 Information Retrieval (外挂双轨深研引擎 - 独立剥离)
*   **架构特征**: 这是原计划挂靠在写作模块中的“找料”功能，现**被物理隔离为独立组件**。
*   **输入**: `Topic Object` 或者大纲给出的局部关键论段。
*   **输出**: 高质量的网综分析源文库、研报引用锚点矩阵（The "Fact-Pack"）。

### 2-A. `global_searcher.py` (外网硬轨爬虫)
*   专攻硬骨干：在收到“大模型价格战”等选题时，自动呼叫 Google / Brave Search，抓取海外科技博客的前沿长篇分析和维基硬知，提供文章高深维度的背书。
### 2-B. `domestic_sniffer.py` (内网情绪探针)
*   专攻共鸣度：去国内知乎或微博抓取高亮帖子、神短评和极具争议的观点，为行文提供纯血本土语境与下沉情绪。
### 2-C. `fact_packer.py` (资料洗练打包机)
*   将上述极其芜杂的外网研报和内网热帖揉平，去除噪音。整理打包为一个超长且极高信噪比的 Background Context（上下文背书垫本），喂给下游工厂。

---

## 模块三：🏭 Article Generator (多 Agent 协作加工厂)
*   **架构特征**: 处于全系统的【绝对中心地带】，纯净无状态，负责内容烹制。它不管搜素，只负责把传入的“话题”和“资料包”煮成一盘大餐。
*   **输入**: `Topic Object` + 模块二送来的超豪华生肉 `Fact-Pack`。
*   **输出**: 3000 字、无幻觉、极其尖锐的纯 Markdown 底稿（无插图）。

### 3-A. `outliner.py` (事件拓扑构图)
*   不负责落笔，只负责用最高级的 Prompt 消化【素材垫本】，生成由起承转合组成的超详尽骨架节点（Tree Outline），甚至定义好哪里要引用模块二找来的数据。

### 3-B. `writer_agents.py` (裂变织肉车间)
*   启动真正的 “多 Agent 并发流水线”：不让一个大模型憋 3000 字。让主管直接把大纲撕成 3 份发给 3 个独立的、设定好口吻的子 Agent。它们互相利用对应的局部 `Fact-Pack` 资料并列疯狂撰写。

### 3-C. `editor_room.py` (毒舌抗压盲测房)
*   三节拼好后，关入“红蓝审稿房”，让设定好极致暴躁人设（例如 `“内容太空洞！不要这些四六骈句，给我痛骂它的伪开源底裤！”`）的总编裁判官审查挑刺。作者打回重写直到阈值放行。

---

## 模块四：🎨 Visual & Layout (微信环境破壁包装厂)
*   **核心宗旨**: 给生硬的文本套上“高端新媒体”外衣。
*   **组件一览**: 
    1. `code_illustrator.py`：读到数据段落立刻用执行 Python 画出折线图插眼。
    2. `flux_vision.py`：呼叫扩散图模补充华美头图。
    3. `mdnice_renderer.py`：剔除 MD 骨架，全篇覆膜 CSS 为成品富文本 HTML。

---

## 模块五：🛡️ Final Delivery (终端大闸：无情挂起与下发)
*   **角色定位**: AI 作者唯一无法擅自突破的权限城墙（生死判官）。
*   **`feishu_reviewer.py`**: 发一个极美排版的飞书文档扔进群，设个 Cron 蹲在角落，死保不见到 `@发布` 不推文的硬桥段规矩。
*   **`matrix_publisher.py`**: 放行的那一秒瞬间将长文揉碎压缩，送去小红书/微薄霸榜。

### 2-A. 在库数据深掘器 (`hot_warehouse_miner.py`) 开发方针
**工作协议**：
*   不要去碰任何公网外链！这是一款纯离线的“超级本地库”检索引擎。
*   **输入**: `List[str] keywords` (大模型或者人类定下的主旨核心词簇，如：`["苹果", "放弃造车", "AI"]`)。
*   **处理逻辑**:
    1.  动态计算日期变量，拿到今天与昨天（最多往前探3天防止过期热点）的格式如 `data/hotnews/daily/2026-02-24_unified.json` 的总仓库据文件地址。
    2.  读入 `json['items']` 后，对于每一条记录，如果它的 `title` 加上 `description` 同时命中了上述 keyword 数组中的**任意几个重要词汇**（模糊命中），则视其为合格的情报源素材。
    3.  对获取到的集合，按照其自带的 `score` 字段（如果存在）作降序排列。
    4.  **裁切防超载**: 大模型很贵且窗口有限。即使找出一万条也只返回 `Top 15`，以防组装 `Fact-Pack` 撑爆 Token。
*   **输出**: `List[Dict]`，即含有平台名、阅读量及提要的精准纯净小字典阵列。

### 3. 多 Agent 孤岛级加工厂 (`article_generator`) 开发方针

此模块为串行数据结构，但在其内部的 B-2 阶段属高并发域。以下为详细技术约束。

**子模块 B-1: `outliner.py` (骨架定盘)**
*   **输入**: `dict Fact-Pack` (由 Retrieval 层透传)。
*   **交互协议**: 必须调取高逻辑模型（配置要求 `deepseek-r1-free` 等）。
*   **System Prompt 约束**: 
    `你是一个冷酷的新闻骨架解剖手。必须输出严格的 JSON。格式必须为：{"title": "<标题>", "sections": [{"name": "<小节标题>", "guidance": "<写作方向>", "quote_req": "<必须引用的上游事实>"}]}`
*   **输出**: 标准字典对象 `Outline`。

**子模块 B-2: `writer_agents.py` (并发组装)**
*   **输入**: 上述 `Outline` 以及全份 `Fact-Pack`。
*   **处理流**:
    1.  利用 `asyncio.gather` 封装 3 个独立的 HTTP 模型请求。
    2.  每一个协程传入独占的 `{"name": "...", "guidance": "..."}`。
    3.  强制拼接。
*   **输出**: 初稿纯文本 `string: draft_v1`。

**子模块 B-3: `editor_room.py` (对喷循环)**
*   **输入**: `draft_v1`。
*   **处理流**:
    1.  定义 `MAX_TURNS = 2`。
    2.  `turn 1` 向模型发送身份：“你是新媒体极度毒舌主编，请找出稿件中陈词滥调并输出修改建议。若完美则输出【过审】”。
    3.  如果不含过审，交由作者模型带入建议修改。
*   **输出**: 抹除 AI 痕迹的二稿文本 `string: final_markdown`。
