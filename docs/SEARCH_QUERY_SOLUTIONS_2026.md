# ä¿¡æ¯æŸ¥è¯¢ä¸æœç´¢æ–¹æ¡ˆç³»ç»Ÿæ€§è°ƒç ” (2026)

> **è°ƒç ”æ—¶é—´**: 2026-02-27
> **è°ƒç ”ç›®æ ‡**: ç³»ç»Ÿæ€§æ¢³ç†æ‰€æœ‰å¯ç”¨çš„æœç´¢/æŸ¥è¯¢ä¿¡æ¯æ–¹æ¡ˆ
> **è°ƒç ”æ–¹æ³•**: web_fetch ç›´æ¥æŠ“å– GitHub é¡¹ç›®æ–‡æ¡£ + å®˜æ–¹æ–‡æ¡£

---

## ğŸ“Š æœç´¢æ–¹æ¡ˆå…¨æ™¯å›¾

### å…­å¤§ç±»æœç´¢æ–¹æ¡ˆ

| ç±»åˆ« | ä»£è¡¨æ–¹æ¡ˆ | æˆæœ¬ | ç¨³å®šæ€§ | æ•°æ®è´¨é‡ | æ¨èåº¦ |
|------|---------|------|--------|---------|--------|
| **æœç´¢å¼•æ“ API** | SerpApi/ZenSERP | ğŸ’°ğŸ’°ğŸ’° | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ |
| **è‡ªæ‰˜ç®¡æœç´¢å¼•æ“** | SearXNG | $0 | â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| **æ— å¤´æµè§ˆå™¨** | Puppeteer+Browserless | $0 | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |
| **å…è´¹ API** | DuckDuckGo éå®˜æ–¹ | $0 | â­â­â­ | â­â­â­ | â­â­â­â­ |
| **å·¥ä½œæµå¹³å°** | n8n/LangChain | $0-ğŸ’° | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ |
| **å…¬å…± API èšåˆ** | Public-APIs | $0 | â­â­â­ | â­â­â­ | â­â­â­ |

---

## ğŸ”¬ æ–¹æ¡ˆä¸€ï¼šæœç´¢å¼•æ“ API (æœ€ç¨³å®š)

### 1.1 SerpApi

**é¡¹ç›®**: https://serpapi.com
**æ”¯æŒå¼•æ“**: Google/Bing/Baidu/Yahoo/DuckDuckGo/eBay/YouTube ç­‰

**ä»·æ ¼**:
- å…è´¹ï¼š100 æ¬¡/æœˆ
- å…¥é—¨ï¼š$50/æœˆ (5000 æ¬¡)
- ä¼ä¸šï¼š$500/æœˆ (æ— é™åˆ¶)

**Python ç¤ºä¾‹**:
```python
from serpapi import GoogleSearch

search = GoogleSearch({
    "q": "AI æ•™è‚²",
    "location": "China",
    "hl": "zh-cn",
    "api_key": "your_api_key"
})
results = search.get_dict()
print(results["organic_results"])
```

**ä¼˜åŠ¿**:
- âœ… æœ€ç¨³å®šå¯é 
- âœ… æ”¯æŒ 70+ æœç´¢å¼•æ“
- âœ… è¿”å›ç»“æ„åŒ– JSON
- âœ… å¤„ç†åçˆ¬/éªŒè¯ç 

**åŠ£åŠ¿**:
- âŒ å…è´¹é¢åº¦æœ‰é™
- âŒ ä»˜è´¹ç‰ˆè¾ƒè´µ

---

### 1.2 ZenSERP

**é¡¹ç›®**: https://zenserp.com
**æ”¯æŒå¼•æ“**: Google/Bing

**ä»·æ ¼**:
- å…è´¹ï¼š1000 æ¬¡/æœˆ
- å…¥é—¨ï¼š$29/æœˆ (5000 æ¬¡)

**API ç¤ºä¾‹**:
```python
import requests

url = "https://api.zenserp.com/search"
params = {
    "apikey": "your_api_key",
    "q": "AI æ•™è‚²",
    "device": "desktop",
    "location": "China"
}

response = requests.get(url, params=params)
results = response.json()
```

---

### 1.3 å…¶ä»–æœç´¢ API

| æœåŠ¡å•† | å…è´¹é¢åº¦ | ä»˜è´¹èµ·ç‚¹ | ç‰¹ç‚¹ |
|--------|---------|---------|------|
| **SerpApi** | 100 æ¬¡/æœˆ | $50/æœˆ | æœ€æˆç†Ÿ |
| **ZenSERP** | 1000 æ¬¡/æœˆ | $29/æœˆ | æ€§ä»·æ¯”é«˜ |
| **ScraperAPI** | 5000 æ¬¡/æœˆ | $29/æœˆ | å†…ç½®ä»£ç† |
| **ScrapingBee** | 1000 æ¬¡/æœˆ | $49/æœˆ | æ”¯æŒ JS |
| **ValueSERP** | 100 æ¬¡/æœˆ | $12/æœˆ | æœ€ä¾¿å®œ |

---

## ğŸ”¬ æ–¹æ¡ˆäºŒï¼šè‡ªæ‰˜ç®¡æœç´¢å¼•æ“ (æ¨è â­â­â­â­â­)

### 2.1 SearXNG

**é¡¹ç›®**: https://github.com/searxng/searxng
**è®¸å¯è¯**: AGPL-3.0

**éƒ¨ç½²**:
```bash
# Docker ä¸€é”®éƒ¨ç½²
docker run -d --name searxng \
  -p 8080:8080 \
  -e BASE_URL=http://localhost:8080/ \
  searxng/searxng
```

**API ä½¿ç”¨**:
```bash
# æœç´¢ API (è¿”å› JSON)
curl "http://localhost:8080/search?q=AI æ•™è‚²&format=json"
```

**è¿”å›æ ¼å¼**:
```json
{
  "query": "AI æ•™è‚²",
  "results": [
    {
      "title": "æ–‡ç« æ ‡é¢˜",
      "url": "https://example.com/article",
      "content": "æ‘˜è¦å†…å®¹...",
      "engine": "google",
      "score": 0.95
    }
  ]
}
```

**é…ç½®ä¼˜åŒ–** (`settings.yml`):
```yaml
search:
  safe_search: 0  # å…³é—­å®‰å…¨è¿‡æ»¤
  autocomplete: "google"
  
engines:
  - name: google
    engine: google
    shortcut: g
    disabled: false
    
  - name: bing
    engine: bing
    shortcut: b
    disabled: false
    
  - name: duckduckgo
    engine: duckduckgo
    shortcut: ddg
    disabled: false
    
  - name: wikipedia
    engine: wikipedia
    shortcut: wp
    disabled: false
```

**ä¼˜åŠ¿**:
- âœ… å®Œå…¨å…è´¹ (è‡ªæ‰˜ç®¡)
- âœ… 70+ æœç´¢æºèšåˆ
- âœ… éšç§ä¿æŠ¤ (ä¸è¿½è¸ª)
- âœ… å¯å®šåˆ¶å¼•æ“
- âœ… æ”¯æŒä¸­æ–‡

**åŠ£åŠ¿**:
- âš ï¸ éœ€è¦è‡ªå·±ç»´æŠ¤æœåŠ¡å™¨
- âš ï¸ éƒ¨åˆ†å¼•æ“å¯èƒ½é™æµ

---

### 2.2 Whoogle Search

**é¡¹ç›®**: https://github.com/benbusby/whoogle-search
**ç‰¹ç‚¹**: ä¸“æ³¨äº Google æœç´¢çš„éšç§å‰ç«¯

**éƒ¨ç½²**:
```bash
docker run -p 5000:5000 benbusby/whoogle-search
```

---

## ğŸ”¬ æ–¹æ¡ˆä¸‰ï¼šæ— å¤´æµè§ˆå™¨ (æœ€çµæ´» â­â­â­â­â­)

### 3.1 Browserless + Puppeteer

**Browserless é¡¹ç›®**: https://github.com/browserless/browserless

**éƒ¨ç½²**:
```bash
# è‡ªæ‰˜ç®¡ Browserless
docker run -p 3000:3000 ghcr.io/browserless/chromium
```

**Puppeteer ä½¿ç”¨**:
```javascript
const puppeteer = require('puppeteer-core');

const browser = await puppeteer.connect({
  browserWSEndpoint: 'ws://localhost:3000',
});

const page = await browser.newPage();
await page.goto('https://www.google.com/search?q=AI æ•™è‚²');

// ç­‰å¾…æœç´¢ç»“æœ
await page.waitForSelector('.g');

// æå–æœç´¢ç»“æœ
const results = await page.evaluate(() => {
  return Array.from(document.querySelectorAll('.g')).map(el => ({
    title: el.querySelector('h3')?.textContent,
    url: el.querySelector('a')?.href,
    snippet: el.querySelector('.VwiC3b')?.textContent
  }));
});

await browser.close();
console.log(results);
```

**Python ç‰ˆæœ¬ (Playwright)**:
```python
from playwright.async_api import async_playwright

async def search_google(query):
    async with async_playwright() as p:
        browser = await p.chromium.connect('ws://localhost:3000')
        page = await browser.new_page()
        await page.goto(f'https://www.google.com/search?q={query}')
        await page.wait_for_selector('.g')
        
        results = await page.evaluate('''() => {
            return Array.from(document.querySelectorAll('.g')).map(el => ({
                title: el.querySelector('h3')?.textContent,
                url: el.querySelector('a')?.href,
                snippet: el.querySelector('.VwiC3b')?.textContent
            }));
        }''')
        
        await browser.close()
        return results
```

**ä¼˜åŠ¿**:
- âœ… å®Œå…¨æ§åˆ¶æœç´¢è¿‡ç¨‹
- âœ… å¯å¤„ç† JS æ¸²æŸ“é¡µé¢
- âœ… å¯æˆªå›¾/å½•å±
- âœ… å¯æ¨¡æ‹Ÿäººç±»è¡Œä¸º
- âœ… è‡ªæ‰˜ç®¡å…è´¹

**åŠ£åŠ¿**:
- âš ï¸ éœ€è¦å¤„ç†åçˆ¬
- âš ï¸ éœ€è¦ç»´æŠ¤æµè§ˆå™¨
- âš ï¸ é€Ÿåº¦è¾ƒæ…¢

---

### 3.2 Selenium

**é¡¹ç›®**: https://github.com/SeleniumHQ/selenium

**Python ç¤ºä¾‹**:
```python
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

options = Options()
options.add_argument('--headless')
options.add_argument('--no-sandbox')

driver = webdriver.Chrome(options=options)
driver.get('https://www.google.com/search?q=AI æ•™è‚²')

results = []
for item in driver.find_elements('.g'):
    try:
        title = item.find_element('css selector', 'h3').text
        url = item.find_element('css selector', 'a').get_attribute('href')
        snippet = item.find_element('css selector', '.VwiC3b').text
        results.append({'title': title, 'url': url, 'snippet': snippet})
    except:
        pass

driver.quit()
```

---

## ğŸ”¬ æ–¹æ¡ˆå››ï¼šå…è´¹ API (æœ€ç®€å•)

### 4.1 DuckDuckGo éå®˜æ–¹ API

**API ç«¯ç‚¹**:
```
https://api.duckduckgo.com/?q=å…³é”®è¯&format=json
```

**Python ç¤ºä¾‹**:
```python
import urllib.request
import json
import urllib.parse

def search_ddg(query):
    url = f"https://api.duckduckgo.com/?q={urllib.parse.quote(query)}&format=json"
    req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
    
    with urllib.request.urlopen(req, timeout=10) as response:
        data = json.loads(response.read().decode('utf-8'))
        
        return {
            "abstract": data.get('Abstract', ''),
            "results": [
                {"title": r.get('text'), "url": r.get('firstUrl')}
                for r in data.get('RelatedTopics', [])
            ]
        }

# æµ‹è¯•
results = search_ddg("AI æ•™è‚²")
print(results)
```

**ä¼˜åŠ¿**:
- âœ… æ— éœ€ API Key
- âœ… å®Œå…¨å…è´¹
- âœ… ç®€å•å¿«é€Ÿ

**åŠ£åŠ¿**:
- âš ï¸ ä»…è¿”å›æ‘˜è¦ (~10 æ¡)
- âš ï¸ ä¸é€‚åˆæ·±åº¦æœç´¢

---

### 4.2 Wikipedia API

**API ç«¯ç‚¹**:
```
https://zh.wikipedia.org/w/api.php
```

**Python ç¤ºä¾‹**:
```python
import requests

def search_wikipedia(query, lang='zh'):
    url = f"https://{lang}.wikipedia.org/w/api.php"
    params = {
        "action": "query",
        "list": "search",
        "srsearch": query,
        "format": "json",
        "srlimit": 10
    }
    
    response = requests.get(url, params=params)
    data = response.json()
    
    return [
        {
            "title": item['title'],
            "snippet": item['snippet'],
            "url": f"https://{lang}.wikipedia.org/wiki/{item['title']}"
        }
        for item in data['query']['search']
    ]

# æµ‹è¯•
results = search_wikipedia("äººå·¥æ™ºèƒ½")
print(results)
```

---

### 4.3 å…¶ä»–å…è´¹ API

| API | ç«¯ç‚¹ | é™åˆ¶ | ç‰¹ç‚¹ |
|-----|------|------|------|
| **DuckDuckGo** | `api.duckduckgo.com` | æ—  | æ‘˜è¦æœç´¢ |
| **Wikipedia** | `wikipedia.org/w/api.php` | æ—  | ç™¾ç§‘æ¡ç›® |
| **OpenWeather** | `api.openweathermap.org` | 60 æ¬¡/åˆ† | å¤©æ°”æ•°æ® |
| **NewsAPI** | `newsapi.org` | 100 æ¬¡/å¤© | æ–°é—»æœç´¢ |
| **Giphy** | `api.giphy.com` | æ—  | GIF æœç´¢ |

---

## ğŸ”¬ æ–¹æ¡ˆäº”ï¼šå·¥ä½œæµå¹³å° (æœ€å¼ºå¤§)

### 5.1 n8n

**é¡¹ç›®**: https://github.com/n8n-io/n8n
**ç‰¹ç‚¹**: å·¥ä½œæµè‡ªåŠ¨åŒ–å¹³å°ï¼Œ400+ é›†æˆ

**éƒ¨ç½²**:
```bash
# Docker éƒ¨ç½²
docker run -d --name n8n -p 5678:5678 docker.n8n.io/n8nio/n8n
```

**æœç´¢å·¥ä½œæµç¤ºä¾‹**:
```
1. HTTP Request èŠ‚ç‚¹ â†’ è°ƒç”¨ SearXNG API
2. Code èŠ‚ç‚¹ â†’ å¤„ç†æœç´¢ç»“æœ
3. HTTP Request èŠ‚ç‚¹ â†’ æŠ“å–ç½‘é¡µå†…å®¹
4. AI èŠ‚ç‚¹ â†’ åˆ†ææ€»ç»“
5. è¾“å‡ºèŠ‚ç‚¹ â†’ ç”ŸæˆæŠ¥å‘Š
```

**ä¼˜åŠ¿**:
- âœ… å¯è§†åŒ–å·¥ä½œæµ
- âœ… 400+ é›†æˆ
- âœ… æ”¯æŒ AI/LLM
- âœ… è‡ªæ‰˜ç®¡å…è´¹

---

### 5.2 LangChain

**é¡¹ç›®**: https://github.com/langchain-ai/langchain
**ç‰¹ç‚¹**: LLM åº”ç”¨å¼€å‘æ¡†æ¶

**æœç´¢å·¥å…·é›†æˆ**:
```python
from langchain_community.tools import DuckDuckGoSearchRun
from langchain.agents import initialize_agent, AgentType
from langchain.llms import OpenAI

# åˆå§‹åŒ–å·¥å…·
search = DuckDuckGoSearchRun()

# åˆ›å»º Agent
llm = OpenAI(temperature=0)
agent = initialize_agent(
    tools=[search],
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION
)

# æ‰§è¡Œæœç´¢
result = agent.run("AI æ•™è‚²çš„æœ€æ–°å‘å±•")
print(result)
```

**ä¼˜åŠ¿**:
- âœ… ä¸ LLM æ·±åº¦é›†æˆ
- âœ… æ”¯æŒå¤šå·¥å…·ç»„åˆ
- âœ… è‡ªåŠ¨æ¨ç†

---

## ğŸ”¬ æ–¹æ¡ˆå…­ï¼šå…¬å…± API èšåˆ

### Public-APIs é¡¹ç›®

**é¡¹ç›®**: https://github.com/public-apis/public-apis
**Stars**: 280K+

**æ”¶å½• API åˆ†ç±»**:
- åŠ¨ç‰©/åŠ¨æ¼«/è‰ºæœ¯
- å•†ä¸š/åŠ å¯†è´§å¸/è´§å¸
- å¼€å‘/æ–‡æ¡£/é‚®ä»¶
- å¨±ä¹/è´¢åŠ¡/é£Ÿå“
- åœ°ç†/æ”¿åºœ/å¥åº·
- æ–°é—»/éŸ³ä¹/ç…§ç‰‡
- ç§‘å­¦/ä½“è‚²/æµ‹è¯•
- å¤©æ°”/è§†é¢‘...

**ä½¿ç”¨æ–¹å¼**:
```python
import requests

# è·å– API åˆ—è¡¨
response = requests.get(
    "https://api.publicapis.org/entries?category=News"
)
apis = response.json()

# ä½¿ç”¨å…·ä½“ API
for api in apis['entries']:
    print(f"{api['API']}: {api['Description']}")
    print(f"  URL: {api['Link']}")
    print(f"  Auth: {api['Auth']}")
    print(f"  HTTPS: {api['HTTPS']}")
```

---

## ğŸ“‹ æ–¹æ¡ˆå¯¹æ¯”æ€»ç»“

### æŒ‰ä½¿ç”¨åœºæ™¯æ¨è

| åœºæ™¯ | æ¨èæ–¹æ¡ˆ | ç†ç”± |
|------|---------|------|
| **å¿«é€ŸéªŒè¯** | DuckDuckGo API | æ— éœ€éƒ¨ç½²ï¼Œç«‹å³ä½¿ç”¨ |
| **ç”Ÿäº§ç¯å¢ƒ** | SerpApi/ZenSERP | æœ€ç¨³å®šå¯é  |
| **æˆæœ¬æ•æ„Ÿ** | SearXNG è‡ªæ‰˜ç®¡ | å®Œå…¨å…è´¹ |
| **æ·±åº¦æŠ“å–** | Browserless+Puppeteer | æœ€çµæ´» |
| **å·¥ä½œæµè‡ªåŠ¨åŒ–** | n8n/LangChain | å¯è§†åŒ–ç¼–æ’ |
| **å­¦æœ¯ç ”ç©¶** | Wikipedia API | æƒå¨æ¥æº |

---

### æŒ‰æˆæœ¬æ’åº

| æ–¹æ¡ˆ | æœˆåº¦æˆæœ¬ | éƒ¨ç½²éš¾åº¦ | ç»´æŠ¤æˆæœ¬ |
|------|---------|---------|---------|
| **DuckDuckGo API** | $0 | ğŸŸ¢ ä½ | ğŸŸ¢ ä½ |
| **SearXNG è‡ªæ‰˜ç®¡** | $5 (VPS) | ğŸŸ¡ ä¸­ | ğŸŸ¢ ä½ |
| **Browserless è‡ªæ‰˜ç®¡** | $5 (VPS) | ğŸŸ¡ ä¸­ | ğŸŸ¢ ä½ |
| **n8n è‡ªæ‰˜ç®¡** | $5 (VPS) | ğŸŸ¡ ä¸­ | ğŸŸ¢ ä½ |
| **ZenSERP** | $29 èµ· | ğŸŸ¢ ä½ | ğŸŸ¢ ä½ |
| **SerpApi** | $50 èµ· | ğŸŸ¢ ä½ | ğŸŸ¢ ä½ |

---

### æŒ‰æ•°æ®è´¨é‡æ’åº

| æ–¹æ¡ˆ | æ•°æ®æº | æ›´æ–°é¢‘ç‡ | å‡†ç¡®æ€§ |
|------|--------|---------|--------|
| **SerpApi** | Google å®˜æ–¹ | å®æ—¶ | â­â­â­â­â­ |
| **SearXNG** | 70+ å¼•æ“ | å®æ—¶ | â­â­â­â­â­ |
| **Browserless** | ç›´æ¥æŠ“å– | å®æ—¶ | â­â­â­â­â­ |
| **DuckDuckGo** | è‡ªæœ‰ç´¢å¼• | å°æ—¶çº§ | â­â­â­â­ |
| **Wikipedia** | ç¤¾åŒºç¼–è¾‘ | å¤©çº§ | â­â­â­â­ |

---

## ğŸ¯ æœ€ç»ˆæ¨è

### æœ€ä½³ç»„åˆæ–¹æ¡ˆ

**ç”Ÿäº§ç¯å¢ƒ**:
```
SearXNG (æœç´¢) + Browserless (æŠ“å–) + LangChain (åˆ†æ)
```

**æˆæœ¬**: $10-15/æœˆ (VPS è´¹ç”¨)
**æ•°æ®è´¨é‡**: â­â­â­â­â­
**ç¨³å®šæ€§**: â­â­â­â­â­

**å¿«é€ŸéªŒè¯**:
```
DuckDuckGo API + LangChain
```

**æˆæœ¬**: $0
**æ•°æ®è´¨é‡**: â­â­â­
**ç¨³å®šæ€§**: â­â­â­â­

---

## ğŸ“š å‚è€ƒèµ„æ–™

### å¼€æºé¡¹ç›®
- [SearXNG](https://github.com/searxng/searxng) - å…ƒæœç´¢å¼•æ“
- [Browserless](https://github.com/browserless/browserless) - Docker åŒ–æµè§ˆå™¨
- [Puppeteer](https://github.com/puppeteer/puppeteer) - Chrome è‡ªåŠ¨åŒ–
- [Selenium](https://github.com/SeleniumHQ/selenium) - æµè§ˆå™¨è‡ªåŠ¨åŒ–
- [n8n](https://github.com/n8n-io/n8n) - å·¥ä½œæµè‡ªåŠ¨åŒ–
- [LangChain](https://github.com/langchain-ai/langchain) - LLM åº”ç”¨æ¡†æ¶
- [Public-APIs](https://github.com/public-apis/public-apis) - å…¬å…± API èšåˆ

### å•†ä¸šæœåŠ¡
- [SerpApi](https://serpapi.com) - æœç´¢ API
- [ZenSERP](https://zenserp.com) - æœç´¢ API
- [ScraperAPI](https://scraperapi.com) - çˆ¬è™« API

---

*è°ƒç ”å®Œæˆæ—¶é—´ï¼š2026-02-27 03:00 UTC+8*
